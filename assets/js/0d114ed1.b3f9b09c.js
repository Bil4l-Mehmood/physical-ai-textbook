"use strict";(self.webpackChunkphysical_ai_textbook=self.webpackChunkphysical_ai_textbook||[]).push([[53],{3087:function(n,e,i){i.r(e),i.d(e,{assets:function(){return l},contentTitle:function(){return o},default:function(){return h},frontMatter:function(){return r},metadata:function(){return t},toc:function(){return d}});var t=JSON.parse('{"id":"chapter-3/3-1-isaac-sim-basics","title":"NVIDIA Isaac Sim: Photorealistic Simulation and Synthetic Data Generation","description":"Master photorealistic robot simulation and generate synthetic training data with NVIDIA Isaac Sim","source":"@site/docs/chapter-3/3-1-isaac-sim-basics.md","sourceDirName":"chapter-3","slug":"/chapter-3/3-1-isaac-sim-basics","permalink":"/physical-ai-textbook/docs/chapter-3/3-1-isaac-sim-basics","draft":false,"unlisted":false,"editUrl":"https://github.com/Bil4l-Mehmood/physical-ai-textbook/edit/main/docs/chapter-3/3-1-isaac-sim-basics.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"sidebar_label":"Lesson 3.1: NVIDIA Isaac Sim","title":"NVIDIA Isaac Sim: Photorealistic Simulation and Synthetic Data Generation","description":"Master photorealistic robot simulation and generate synthetic training data with NVIDIA Isaac Sim","duration":120,"difficulty":"Advanced","hardware":["Ubuntu 22.04 LTS","NVIDIA GPU RTX 4070+ (12GB VRAM min)","ROS 2 Humble","NVIDIA Isaac Sim 4.0+"],"prerequisites":["Lesson 2.3: Sensor Simulation & Unity Integration"]},"sidebar":"tutorialSidebar","previous":{"title":"Lesson 2.3: Sensors & Unity","permalink":"/physical-ai-textbook/docs/chapter-2/2-3-sensors-unity"},"next":{"title":"Lesson 3.2: VSLAM & Navigation","permalink":"/physical-ai-textbook/docs/chapter-3/3-2-vslam-navigation"}}'),a=i(4848),s=i(8453);const r={sidebar_position:1,sidebar_label:"Lesson 3.1: NVIDIA Isaac Sim",title:"NVIDIA Isaac Sim: Photorealistic Simulation and Synthetic Data Generation",description:"Master photorealistic robot simulation and generate synthetic training data with NVIDIA Isaac Sim",duration:120,difficulty:"Advanced",hardware:["Ubuntu 22.04 LTS","NVIDIA GPU RTX 4070+ (12GB VRAM min)","ROS 2 Humble","NVIDIA Isaac Sim 4.0+"],prerequisites:["Lesson 2.3: Sensor Simulation & Unity Integration"]},o="Lesson 3.1: NVIDIA Isaac Sim - Photorealistic Robot Simulation",l={},d=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Hardware Requirements",id:"hardware-requirements",level:2},{value:"Minimum Specifications",id:"minimum-specifications",level:3},{value:"Hardware Alternatives",id:"hardware-alternatives",level:3},{value:"Part 1: NVIDIA Isaac Ecosystem Overview",id:"part-1-nvidia-isaac-ecosystem-overview",level:2},{value:"Isaac Components",id:"isaac-components",level:3},{value:"Why NVIDIA Isaac for Physical AI",id:"why-nvidia-isaac-for-physical-ai",level:3},{value:"Part 2: Installation &amp; Setup",id:"part-2-installation--setup",level:2},{value:"Step 1: System Verification",id:"step-1-system-verification",level:3},{value:"Step 2: Download Isaac Sim",id:"step-2-download-isaac-sim",level:3},{value:"Step 3: Verify Installation",id:"step-3-verify-installation",level:3},{value:"Step 4: Configure ROS 2 Integration",id:"step-4-configure-ros-2-integration",level:3},{value:"Part 3: Core Concepts - USD and PhysX",id:"part-3-core-concepts---usd-and-physx",level:2},{value:"Universal Scene Description (USD)",id:"universal-scene-description-usd",level:3},{value:"PhysX Physics Engine",id:"physx-physics-engine",level:3},{value:"Part 4: Creating a Simulation Environment",id:"part-4-creating-a-simulation-environment",level:2},{value:"Method 1: Using UI (Visual Building)",id:"method-1-using-ui-visual-building",level:3},{value:"Method 2: Python Scripting (Programmatic)",id:"method-2-python-scripting-programmatic",level:3},{value:"Part 5: Synthetic Data Generation for Training",id:"part-5-synthetic-data-generation-for-training",level:2},{value:"Generating Annotated Training Data",id:"generating-annotated-training-data",level:3},{value:"Part 6: ROS 2 Integration",id:"part-6-ros-2-integration",level:2},{value:"Controlling Isaac Sim Robot from ROS 2",id:"controlling-isaac-sim-robot-from-ros-2",level:3},{value:"Hands-On Exercise",id:"hands-on-exercise",level:2},{value:"Step 1: Create Isaac Sim Project",id:"step-1-create-isaac-sim-project",level:3},{value:"Step 2: Generate Synthetic Data",id:"step-2-generate-synthetic-data",level:3},{value:"Step 3: Control with ROS 2",id:"step-3-control-with-ros-2",level:3},{value:"Exercises",id:"exercises",level:3},{value:"Common Issues &amp; Troubleshooting",id:"common-issues--troubleshooting",level:2},{value:"Key Takeaways",id:"key-takeaways",level:2},{value:"Further Reading",id:"further-reading",level:2}];function c(n){const e={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...n.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.header,{children:(0,a.jsx)(e.h1,{id:"lesson-31-nvidia-isaac-sim---photorealistic-robot-simulation",children:"Lesson 3.1: NVIDIA Isaac Sim - Photorealistic Robot Simulation"})}),"\n",(0,a.jsxs)(e.admonition,{title:"Lesson Overview",type:"info",children:[(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Duration"}),": 120 minutes | ",(0,a.jsx)(e.strong,{children:"Difficulty"}),": Advanced | ",(0,a.jsx)(e.strong,{children:"Hardware"}),": Ubuntu 22.04 + NVIDIA RTX GPU + Isaac Sim"]}),(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Prerequisites"}),": Chapter 1-2 complete (ROS 2, Gazebo, sensors)"]}),(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Learning Outcome"}),": Master photorealistic simulation, synthetic data generation, and sim-to-real transfer with NVIDIA Isaac Sim"]})]}),"\n",(0,a.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,a.jsx)(e.p,{children:"By the end of this lesson, you will be able to:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Understand NVIDIA Isaac ecosystem architecture"}),"\n",(0,a.jsx)(e.li,{children:"Set up Isaac Sim on NVIDIA hardware"}),"\n",(0,a.jsx)(e.li,{children:"Create photorealistic environments using Universal Scene Description (USD)"}),"\n",(0,a.jsx)(e.li,{children:"Simulate robots with accurate physics and rendering"}),"\n",(0,a.jsx)(e.li,{children:"Generate synthetic training data for machine learning"}),"\n",(0,a.jsx)(e.li,{children:"Configure domain randomization for sim-to-real transfer"}),"\n",(0,a.jsx)(e.li,{children:"Integrate Isaac Sim with ROS 2 for robot control"}),"\n",(0,a.jsx)(e.li,{children:"Optimize simulation performance for real-time control"}),"\n",(0,a.jsx)(e.li,{children:"Deploy trained models to real robots"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"hardware-requirements",children:"Hardware Requirements"}),"\n",(0,a.jsxs)(e.admonition,{title:"Hardware Demanding",type:"warning",children:[(0,a.jsx)(e.p,{children:"Isaac Sim requires industrial-grade GPU hardware due to:"}),(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Photorealistic rendering"}),": Ray tracing requires RTX (NVIDIA's ray-tracing cores)"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Physics simulation"}),": Complex dynamics with multiple robots"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Synthetic data generation"}),": High-resolution images at 100+ FPS"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Machine learning"}),": Training perception models simultaneously"]}),"\n"]})]}),"\n",(0,a.jsx)(e.h3,{id:"minimum-specifications",children:"Minimum Specifications"}),"\n",(0,a.jsxs)(e.table,{children:[(0,a.jsx)(e.thead,{children:(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.th,{children:"Component"}),(0,a.jsx)(e.th,{children:"Requirement"}),(0,a.jsx)(e.th,{children:"Rationale"})]})}),(0,a.jsxs)(e.tbody,{children:[(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:(0,a.jsx)(e.strong,{children:"GPU"})}),(0,a.jsx)(e.td,{children:"NVIDIA RTX 4070 (12GB) or better"}),(0,a.jsx)(e.td,{children:"Ray tracing + simulation"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:(0,a.jsx)(e.strong,{children:"VRAM"})}),(0,a.jsx)(e.td,{children:"12 GB minimum (24 GB recommended)"}),(0,a.jsx)(e.td,{children:"USD asset loading, training models"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:(0,a.jsx)(e.strong,{children:"CPU"})}),(0,a.jsx)(e.td,{children:"Intel i7-13th Gen or AMD Ryzen 9"}),(0,a.jsx)(e.td,{children:"Physics calculations, parallel inference"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:(0,a.jsx)(e.strong,{children:"RAM"})}),(0,a.jsx)(e.td,{children:"64 GB DDR5"}),(0,a.jsx)(e.td,{children:"Multiple environments, data generation"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:(0,a.jsx)(e.strong,{children:"Storage"})}),(0,a.jsx)(e.td,{children:"500 GB NVMe SSD"}),(0,a.jsx)(e.td,{children:"Isaac Sim installation + datasets"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:(0,a.jsx)(e.strong,{children:"OS"})}),(0,a.jsx)(e.td,{children:"Ubuntu 22.04 LTS"}),(0,a.jsx)(e.td,{children:"Official support, ROS 2 Humble compatibility"})]})]})]}),"\n",(0,a.jsx)(e.h3,{id:"hardware-alternatives",children:"Hardware Alternatives"}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Option A: Local Workstation (Recommended)"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Highest performance, lowest latency"}),"\n",(0,a.jsx)(e.li,{children:"Can iterate quickly during development"}),"\n",(0,a.jsx)(e.li,{children:"Ideal for sim-to-real transfer training"}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Option B: Cloud GPU Instances"})}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{children:"AWS g5.2xlarge (A10G GPU, 24GB)\n\u251c\u2500 Training: $1.50/hour\n\u251c\u2500 Total per quarter: ~$205 (120 hours)\n\u2514\u2500 Plus data storage: $25/month\n"})}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Option C: NVIDIA Omniverse Cloud"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Native NVIDIA infrastructure"}),"\n",(0,a.jsx)(e.li,{children:"Optimized for Isaac Sim"}),"\n",(0,a.jsx)(e.li,{children:"Seamless ROS 2 integration"}),"\n",(0,a.jsx)(e.li,{children:"Cost: ~$3,000/quarter for power users"}),"\n"]}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.h2,{id:"part-1-nvidia-isaac-ecosystem-overview",children:"Part 1: NVIDIA Isaac Ecosystem Overview"}),"\n",(0,a.jsx)(e.h3,{id:"isaac-components",children:"Isaac Components"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Isaac Sim"})," (This lesson)"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Photorealistic 3D environment"}),"\n",(0,a.jsx)(e.li,{children:"Physics simulation with Nvidia PhysX"}),"\n",(0,a.jsx)(e.li,{children:"Synthetic data generation"}),"\n",(0,a.jsx)(e.li,{children:"Domain randomization"}),"\n",(0,a.jsx)(e.li,{children:"Ray-tracing visualization"}),"\n"]}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Isaac ROS"})," (Lesson 3.2)"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Hardware-accelerated perception pipeline"}),"\n",(0,a.jsx)(e.li,{children:"VSLAM (Visual Simultaneous Localization and Mapping)"}),"\n",(0,a.jsx)(e.li,{children:"Navigation stack"}),"\n",(0,a.jsx)(e.li,{children:"Computer vision processing"}),"\n"]}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Isaac SDK"})," (Advanced - not covered)"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Development toolkit"}),"\n",(0,a.jsx)(e.li,{children:"Custom perception nodes"}),"\n",(0,a.jsx)(e.li,{children:"Reinforcement learning training"}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"why-nvidia-isaac-for-physical-ai",children:"Why NVIDIA Isaac for Physical AI"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{children:"Traditional Pipeline           \u2192  NVIDIA Isaac Pipeline\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502Real Robots  \u2502  (Expensive)    \u2502Photorealistic Sim\u2502\n\u2502  Sensors    \u2502  (Slow)          \u2502Synthetic Data    \u2502\n\u2502Data Collect \u2502  (Dangerous)     \u2502Domain Random     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n      \u2193                                 \u2193\n Manual Labels                    Automated Generation\n      \u2193                                 \u2193\n ML Training  (Weeks)            ML Training (Days)\n      \u2193                                 \u2193\n Real Robot   (1-2x)             Sim-to-Real (90%+ success)\n"})}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Benefits"}),":"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Generate 1M images in 24 hours (vs weeks on real robots)"}),"\n",(0,a.jsx)(e.li,{children:"Perfect ground truth annotations (auto-generated)"}),"\n",(0,a.jsx)(e.li,{children:"Infinitely variable conditions (no manual diversity)"}),"\n",(0,a.jsx)(e.li,{children:"Zero robot wear/damage during training"}),"\n",(0,a.jsx)(e.li,{children:"10-100x faster iteration cycle"}),"\n"]}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.h2,{id:"part-2-installation--setup",children:"Part 2: Installation & Setup"}),"\n",(0,a.jsx)(e.h3,{id:"step-1-system-verification",children:"Step 1: System Verification"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-bash",children:'# Check GPU\nnvidia-smi\n# Should show: NVIDIA RTX 4070/4080/4090 or A10G\n\n# Verify NVIDIA drivers (should be 525+)\nnvidia-smi | grep "Driver Version"\n\n# Check disk space for Isaac installation\ndf -h /\n# Need: 100GB free for Isaac Sim + datasets\n\n# Verify Ubuntu version\nlsb_release -d\n# Should be: Ubuntu 22.04 LTS\n'})}),"\n",(0,a.jsx)(e.h3,{id:"step-2-download-isaac-sim",children:"Step 2: Download Isaac Sim"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-bash",children:'# Create installation directory\nmkdir -p ~/nvidia_omniverse\ncd ~/nvidia_omniverse\n\n# Option A: Download from NVIDIA Launcher\n# 1. Go to https://www.nvidia.com/en-us/omniverse/\n# 2. Download "Omniverse Launcher"\n# 3. Install and log in\n# 4. Install "Isaac Sim" from launcher\n\n# Option B: Command-line installation (requires auth)\n# NVIDIA_TOKEN=your_token ./isaac_sim_installer.sh\n'})}),"\n",(0,a.jsx)(e.h3,{id:"step-3-verify-installation",children:"Step 3: Verify Installation"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-bash",children:"# Launch Isaac Sim\n~/nvidia_omniverse/isaac_sim/isaac_sim.sh\n\n# Expected: Omniverse Isaac Sim window opens\n# Shows default scene with robot(s)\n"})}),"\n",(0,a.jsx)(e.h3,{id:"step-4-configure-ros-2-integration",children:"Step 4: Configure ROS 2 Integration"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-bash",children:'# Inside Isaac Sim, install ROS 2 Bridge\n# Extensions \u2192 Search "ROS2"\n# Enable: "ROS2 Bridge" extension\n\n# Verify ROS 2 topics available\nsource /opt/ros/humble/setup.bash\nros2 topic list\n# Should show Isaac-generated topics\n'})}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.h2,{id:"part-3-core-concepts---usd-and-physx",children:"Part 3: Core Concepts - USD and PhysX"}),"\n",(0,a.jsx)(e.h3,{id:"universal-scene-description-usd",children:"Universal Scene Description (USD)"}),"\n",(0,a.jsx)(e.p,{children:"USD is the 3D format used by Isaac Sim (and industry standard):"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'# Simple USD robot description\n#usda 1.0\n(\n    defaultPrim = "World"\n)\n\ndef Xform "World"\n{\n    def Mesh "base_link"\n    {\n        # Visual geometry\n        int[] faceVertexCounts = [4, 4, 4, 4, 4, 4]\n        int[] faceVertexIndices = [...]\n        point3f[] points = [...]\n\n        # Physics material\n        rel material:binding = </Materials/Plastic>\n    }\n\n    def Mesh "link_1"\n    {\n        # Joint transform\n        matrix4d xformOp:transform = (...)\n\n        # Collision geometry\n        custom bool physics:enabled = true\n        custom float physics:mass = 0.5\n    }\n}\n'})}),"\n",(0,a.jsx)(e.h3,{id:"physx-physics-engine",children:"PhysX Physics Engine"}),"\n",(0,a.jsx)(e.p,{children:"NVIDIA's proprietary physics engine (used in Isaac Sim):"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Advantages over ODE/Bullet"}),":"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"GPU-accelerated calculations"}),"\n",(0,a.jsx)(e.li,{children:"Better humanoid dynamics"}),"\n",(0,a.jsx)(e.li,{children:"Deterministic simulation"}),"\n",(0,a.jsx)(e.li,{children:"Cloth and soft body support"}),"\n",(0,a.jsx)(e.li,{children:"More realistic contact/friction"}),"\n"]}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Configuration in USD"}),":"]}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'def Xform "Physics"\n{\n    # Time stepping\n    float timeCodesPerSecond = 30.0\n\n    # Gravity\n    vector3f gravity = (0, 0, -9.81)\n\n    # Solver\n    uint solverType = 1  # TGS solver (1) or PGS (0)\n    uint broadphaseType = 0\n    uint narrowphaseType = 1\n    uint constraintType = 2\n}\n'})}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.h2,{id:"part-4-creating-a-simulation-environment",children:"Part 4: Creating a Simulation Environment"}),"\n",(0,a.jsx)(e.h3,{id:"method-1-using-ui-visual-building",children:"Method 1: Using UI (Visual Building)"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{children:'1. Launch Isaac Sim\n2. File \u2192 New \u2192 Empty Stage\n3. Layout \u2192 Change to "Perspective" view\n4. Add Ground Plane:\n   - Create \u2192 Mesh \u2192 Ground Plane\n5. Add Robot:\n   - File \u2192 Open \u2192 your_robot.usd\n6. Add Lights:\n   - Create \u2192 Light \u2192 Sphere\n   - Create \u2192 Light \u2192 Directional (sun)\n7. Configure Physics:\n   - Window \u2192 Physics\n   - Set gravity, solver type\n8. Save As: my_world.usd\n'})}),"\n",(0,a.jsx)(e.h3,{id:"method-2-python-scripting-programmatic",children:"Method 2: Python Scripting (Programmatic)"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\n"""\nCreate Isaac Sim environment programmatically\n"""\n\nimport omni.kit.app\nfrom omni.isaac.core import World\nfrom omni.isaac.core.utils.stage import create_new_stage\nfrom omni.isaac.core.utils.prims import delete_prim\nfrom omni.isaac.core.physics_context import PhysicsContext\nfrom omni.isaac.core.robots import Robot\nfrom pxr import Usd, UsdGeom\n\n\ndef create_simulation_world():\n    """\n    Create a complete Isaac Sim environment with:\n    - Ground plane\n    - Lighting\n    - Physics configuration\n    - Robot model\n    """\n\n    # Initialize stage\n    create_new_stage()\n    stage = omni.usd.get_context().get_stage()\n\n    # Create world\n    world = World(stage=stage)\n    world.scene.add_ground_plane()\n\n    # Configure physics\n    physics_context = PhysicsContext(\n        stage=stage,\n        physics_dt=1.0/60.0,  # 60 Hz simulation\n        rendering_dt=1.0/30.0,  # 30 Hz rendering\n        gravity=(0, 0, -9.81),\n        solver_type="TGS"  # NVIDIA TGS solver\n    )\n\n    # Add lighting\n    stage.DefinePrim("/World/Lighting/sun", "Xform")\n    light = UsdGeom.Sphere.Define(stage, "/World/Lighting/sun")\n    light.GetRadiusAttr().Set(1)\n\n    # Load robot\n    robot_usd_path = "/home/user/robots/humanoid.usd"\n    stage.DefinePrim("/World/robot", "Xform").GetReferences().AddReference(robot_usd_path)\n\n    # Set robot pose\n    stage.GetPrimAtPath("/World/robot").GetAttribute("xformOp:translate").Set((0, 0, 1))\n\n    # Save stage\n    stage.Export("/home/user/my_simulation.usd")\n\n    print("\u2705 Simulation environment created")\n\n\nif __name__ == "__main__":\n    create_simulation_world()\n'})}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.h2,{id:"part-5-synthetic-data-generation-for-training",children:"Part 5: Synthetic Data Generation for Training"}),"\n",(0,a.jsx)(e.h3,{id:"generating-annotated-training-data",children:"Generating Annotated Training Data"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\n"""\nGenerate synthetic training dataset with automatic annotations\n"""\n\nimport omni.kit.app\nimport numpy as np\nfrom PIL import Image\nimport json\nimport os\n\n\nclass SyntheticDataGenerator:\n    """Generate annotated synthetic data for ML training"""\n\n    def __init__(self, output_dir="/tmp/synthetic_data"):\n        self.output_dir = output_dir\n        self.image_dir = os.path.join(output_dir, "images")\n        self.labels_dir = os.path.join(output_dir, "labels")\n        self.metadata_dir = os.path.join(output_dir, "metadata")\n\n        # Create directories\n        os.makedirs(self.image_dir, exist_ok=True)\n        os.makedirs(self.labels_dir, exist_ok=True)\n        os.makedirs(self.metadata_dir, exist_ok=True)\n\n    def randomize_domain(self, iteration):\n        """\n        Apply domain randomization to make sim-to-real transfer effective:\n        - Vary lighting conditions\n        - Change material properties\n        - Randomize object positions\n        - Add camera noise\n        """\n\n        # Lighting variation\n        light_intensity = np.random.uniform(0.5, 2.0)\n        light_color = np.random.uniform([0.5, 0.5, 0.5], [1.0, 1.0, 1.0])\n        # Apply to Isaac Sim light\n\n        # Texture variation (metallic, roughness, color)\n        material_properties = {\n            "metallic": np.random.uniform(0.0, 1.0),\n            "roughness": np.random.uniform(0.1, 0.9),\n            "color": {\n                "r": np.random.uniform(0.2, 1.0),\n                "g": np.random.uniform(0.2, 1.0),\n                "b": np.random.uniform(0.2, 1.0)\n            }\n        }\n\n        # Object pose randomization\n        poses = {\n            "robot_x": np.random.uniform(-2, 2),\n            "robot_y": np.random.uniform(-2, 2),\n            "robot_z": 0.5,\n            "camera_angle": np.random.uniform(-30, 30)  # degrees\n        }\n\n        # Camera noise (Gaussian noise in image)\n        camera_noise = np.random.normal(0, 5, (480, 640, 3))\n\n        return {\n            "iteration": iteration,\n            "lighting": {\n                "intensity": light_intensity,\n                "color": light_color.tolist()\n            },\n            "materials": material_properties,\n            "poses": poses,\n            "camera_noise_stddev": 5.0\n        }\n\n    def generate_frame(self, iteration, rgb_image, depth_image, segmentation):\n        """\n        Save frame with automatic annotations\n        """\n\n        # Save RGB image\n        image_filename = f"frame_{iteration:06d}.png"\n        image_path = os.path.join(self.image_dir, image_filename)\n        Image.fromarray(rgb_image).save(image_path)\n\n        # Save depth image (as 16-bit grayscale)\n        depth_filename = f"depth_{iteration:06d}.png"\n        depth_path = os.path.join(self.image_dir, depth_filename)\n        depth_normalized = (depth_image / depth_image.max() * 65535).astype(np.uint16)\n        Image.fromarray(depth_normalized).save(depth_path)\n\n        # Save segmentation mask\n        seg_filename = f"segmentation_{iteration:06d}.png"\n        seg_path = os.path.join(self.image_dir, seg_filename)\n        Image.fromarray(segmentation).save(seg_path)\n\n        # Save annotations as JSON\n        randomization = self.randomize_domain(iteration)\n        annotations = {\n            "image_id": iteration,\n            "image_file": image_filename,\n            "depth_file": depth_filename,\n            "segmentation_file": seg_filename,\n            "width": 640,\n            "height": 480,\n            "camera_fx": 554.254,  # Intrinsics\n            "camera_fy": 554.254,\n            "camera_cx": 320.0,\n            "camera_cy": 240.0,\n            "objects": [\n                {\n                    "id": 1,\n                    "name": "robot",\n                    "bbox": [100, 100, 200, 300],  # x, y, width, height\n                    "segmentation_id": 1,\n                    "pose": {\n                        "x": randomization["poses"]["robot_x"],\n                        "y": randomization["poses"]["robot_y"],\n                        "z": randomization["poses"]["robot_z"]\n                    }\n                }\n            ],\n            "randomization": randomization\n        }\n\n        # Save JSON annotation\n        label_filename = f"frame_{iteration:06d}.json"\n        label_path = os.path.join(self.labels_dir, label_filename)\n        with open(label_path, \'w\') as f:\n            json.dump(annotations, f, indent=2)\n\n        return image_path, label_path\n\n    def generate_dataset(self, num_frames=1000):\n        """Generate complete training dataset"""\n\n        for frame_idx in range(num_frames):\n            # Simulate rendering (in real code, capture from Isaac Sim)\n            rgb = np.random.randint(0, 256, (480, 640, 3), dtype=np.uint8)\n            depth = np.random.uniform(0.1, 10.0, (480, 640)).astype(np.float32)\n            seg = np.random.randint(0, 10, (480, 640), dtype=np.uint8)\n\n            self.generate_frame(frame_idx, rgb, depth, seg)\n\n            if frame_idx % 100 == 0:\n                print(f"\u2705 Generated {frame_idx}/{num_frames} frames")\n\n        # Create dataset manifest\n        manifest = {\n            "total_frames": num_frames,\n            "output_directory": self.output_dir,\n            "format": "COCO",\n            "image_size": [640, 480],\n            "camera_model": "pinhole"\n        }\n\n        with open(os.path.join(self.metadata_dir, "manifest.json"), \'w\') as f:\n            json.dump(manifest, f, indent=2)\n\n        print(f"\u2705 Dataset complete: {num_frames} frames in {self.output_dir}")\n\n\nif __name__ == "__main__":\n    generator = SyntheticDataGenerator("/tmp/synthetic_training_data")\n    generator.generate_dataset(num_frames=10000)\n'})}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.h2,{id:"part-6-ros-2-integration",children:"Part 6: ROS 2 Integration"}),"\n",(0,a.jsx)(e.h3,{id:"controlling-isaac-sim-robot-from-ros-2",children:"Controlling Isaac Sim Robot from ROS 2"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\n"""\nControl Isaac Sim robot using ROS 2 joint commands\n"""\n\nimport rclpy\nfrom rclpy.node import Node\nfrom trajectory_msgs.msg import JointTrajectory, JointTrajectoryPoint\nfrom sensor_msgs.msg import JointState\nimport math\nimport time\n\n\nclass IsaacSimController(Node):\n    """Send joint commands to Isaac Sim simulated robot"""\n\n    def __init__(self):\n        super().__init__(\'isaac_sim_controller\')\n\n        # Publisher for joint trajectory commands\n        self.joint_traj_pub = self.create_publisher(\n            JointTrajectory,\n            \'/isaac_sim/joint_trajectory_controller/commands\',\n            10\n        )\n\n        # Subscriber for joint state feedback\n        self.joint_state_sub = self.create_subscription(\n            JointState,\n            \'/isaac_sim/joint_states\',\n            self.joint_state_callback,\n            10\n        )\n\n        self.current_joint_positions = {}\n        self.get_logger().info(\'Isaac Sim controller initialized\')\n\n    def joint_state_callback(self, msg):\n        """Monitor current joint states from simulation"""\n        for i, name in enumerate(msg.name):\n            self.current_joint_positions[name] = msg.position[i]\n\n    def send_joint_command(self, joint_targets, duration=1.0):\n        """\n        Send joint position command to Isaac Sim\n\n        Args:\n            joint_targets: Dict of {joint_name: target_position}\n            duration: Time to reach target (seconds)\n        """\n\n        traj = JointTrajectory()\n        traj.header.stamp = self.get_clock().now().to_msg()\n        traj.joint_names = list(joint_targets.keys())\n\n        point = JointTrajectoryPoint()\n        point.positions = list(joint_targets.values())\n        point.time_from_start.sec = int(duration)\n        point.time_from_start.nanosec = int((duration % 1) * 1e9)\n\n        traj.points.append(point)\n        self.joint_traj_pub.publish(traj)\n\n        self.get_logger().info(f\'Sent joint command: {joint_targets}\')\n\n    def walk_forward(self):\n        """Make humanoid walk forward"""\n\n        # Simplified bipedal walking sequence\n        walking_sequence = [\n            {"left_hip": 0.0, "right_hip": 0.0},\n            {"left_hip": 0.5, "right_hip": -0.5},\n            {"left_hip": 0.0, "right_hip": 0.0},\n            {"left_hip": -0.5, "right_hip": 0.5},\n        ]\n\n        for pose in walking_sequence:\n            self.send_joint_command(pose, duration=0.5)\n            time.sleep(0.6)  # Wait for movement to complete\n\n        self.get_logger().info(\'\u2705 Walking sequence complete\')\n\n\ndef main(args=None):\n    rclpy.init(args=args)\n    controller = IsaacSimController()\n\n    # Execute walking pattern\n    controller.walk_forward()\n\n    controller.destroy_node()\n    rclpy.shutdown()\n\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.h2,{id:"hands-on-exercise",children:"Hands-On Exercise"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Task"}),": Create a photorealistic Isaac Sim environment with a robot, generate synthetic data, and control it with ROS 2."]}),"\n",(0,a.jsx)(e.h3,{id:"step-1-create-isaac-sim-project",children:"Step 1: Create Isaac Sim Project"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-bash",children:"# Launch Isaac Sim\n~/nvidia_omniverse/isaac_sim/isaac_sim.sh\n\n# In the UI:\n# 1. File \u2192 New\n# 2. Create \u2192 Xform (ground plane)\n# 3. File \u2192 Open \u2192 Load your robot.usd\n# 4. Configure physics: Physics at top\n# 5. Save as: my_robot_world.usd\n"})}),"\n",(0,a.jsx)(e.h3,{id:"step-2-generate-synthetic-data",children:"Step 2: Generate Synthetic Data"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-bash",children:"# Create data generation script\ncat > ~/isaac_data_gen.py << 'EOF'\n# (Paste SyntheticDataGenerator code from Part 5)\nEOF\n\npython3 ~/isaac_data_gen.py\n# Output: 10,000 annotated frames in ~/synthetic_training_data/\n"})}),"\n",(0,a.jsx)(e.h3,{id:"step-3-control-with-ros-2",children:"Step 3: Control with ROS 2"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-bash",children:"# Terminal 1: Isaac Sim\n~/nvidia_omniverse/isaac_sim/isaac_sim.sh\n\n# Terminal 2: ROS 2 controller\nsource /opt/ros/humble/setup.bash\npython3 ~/isaac_sim_controller.py\n"})}),"\n",(0,a.jsx)(e.h3,{id:"exercises",children:"Exercises"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Domain Randomization"}),": Vary lighting 100 times and save dataset"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Data Annotation"}),": Verify JSON labels match images"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Robot Control"}),": Implement complete walking cycle"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Camera Calibration"}),": Adjust camera intrinsics and compare with real camera"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Reinforcement Learning"}),": Train a simple policy with generated data"]}),"\n"]}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.h2,{id:"common-issues--troubleshooting",children:"Common Issues & Troubleshooting"}),"\n",(0,a.jsxs)(e.table,{children:[(0,a.jsx)(e.thead,{children:(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.th,{children:"Issue"}),(0,a.jsx)(e.th,{children:"Cause"}),(0,a.jsx)(e.th,{children:"Solution"})]})}),(0,a.jsxs)(e.tbody,{children:[(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:"Isaac Sim won't launch"}),(0,a.jsx)(e.td,{children:"GPU driver outdated"}),(0,a.jsx)(e.td,{children:"Update NVIDIA drivers to 525+"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:"Low FPS (<20)"}),(0,a.jsx)(e.td,{children:"Simulation too complex"}),(0,a.jsx)(e.td,{children:"Reduce object count, use simpler meshes"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:"ROS 2 topics empty"}),(0,a.jsx)(e.td,{children:"Bridge not enabled"}),(0,a.jsx)(e.td,{children:'Extension \u2192 Enable "ROS2 Bridge"'})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:"Synthetic data blurry"}),(0,a.jsx)(e.td,{children:"Rendering resolution low"}),(0,a.jsx)(e.td,{children:"Physics \u2192 Rendering DPI scale 2.0"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:"Physics unstable"}),(0,a.jsx)(e.td,{children:"Solver type wrong"}),(0,a.jsx)(e.td,{children:"Use TGS (type 1) instead of PGS"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:"Memory errors"}),(0,a.jsx)(e.td,{children:"VRAM exhausted"}),(0,a.jsx)(e.td,{children:"Reduce image resolution, use fewer environments"})]})]})]}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,a.jsxs)(e.p,{children:["\u2705 ",(0,a.jsx)(e.strong,{children:"Isaac Ecosystem"}),": Simulation (Isaac Sim) + Perception (Isaac ROS) + Training"]}),"\n",(0,a.jsxs)(e.p,{children:["\u2705 ",(0,a.jsx)(e.strong,{children:"Photorealistic Rendering"}),": Ray tracing for sim-to-real transfer effectiveness"]}),"\n",(0,a.jsxs)(e.p,{children:["\u2705 ",(0,a.jsx)(e.strong,{children:"Synthetic Data"}),": Generate 1M annotated frames in hours, not weeks"]}),"\n",(0,a.jsxs)(e.p,{children:["\u2705 ",(0,a.jsx)(e.strong,{children:"Domain Randomization"}),": Vary lighting/materials/poses to bridge sim-to-real gap"]}),"\n",(0,a.jsxs)(e.p,{children:["\u2705 ",(0,a.jsx)(e.strong,{children:"ROS 2 Native"}),": Direct integration with ROS 2 control stacks"]}),"\n",(0,a.jsxs)(e.p,{children:["\u2705 ",(0,a.jsx)(e.strong,{children:"Hardware Demanding"}),": RTX 4070+ GPU required for real-time simulation"]}),"\n",(0,a.jsxs)(e.p,{children:["\u2705 ",(0,a.jsx)(e.strong,{children:"GPU Physics"}),": NVIDIA PhysX enables accurate humanoid dynamics"]}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.h2,{id:"further-reading",children:"Further Reading"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:["\ud83d\udcd6 ",(0,a.jsx)(e.a,{href:"https://docs.omniverse.nvidia.com/isaacsim/latest/",children:"NVIDIA Isaac Sim Documentation"})]}),"\n",(0,a.jsxs)(e.li,{children:["\ud83d\udcd6 ",(0,a.jsx)(e.a,{href:"https://graphics.pixar.com/usd/docs/index.html",children:"USD Specification"})]}),"\n",(0,a.jsxs)(e.li,{children:["\ud83d\udcd6 ",(0,a.jsx)(e.a,{href:"https://nvlabs.github.io/sim-to-real-robotics/",children:"Sim-to-Real Transfer Guide"})]}),"\n",(0,a.jsxs)(e.li,{children:["\ud83d\udcd6 ",(0,a.jsx)(e.a,{href:"https://arxiv.org/abs/1703.06907",children:"Domain Randomization Paper"})]}),"\n"]}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Next Lesson"}),": ",(0,a.jsx)(e.a,{href:"/physical-ai-textbook/docs/chapter-3/3-2-vslam-navigation",children:"Lesson 3.2: VSLAM & Navigation with Isaac ROS"})]}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Questions?"})," See ",(0,a.jsx)(e.a,{href:"/physical-ai-textbook/docs/faq",children:"FAQ"})," or ",(0,a.jsx)(e.a,{href:"https://github.com/physical-ai-course/physical-ai-textbook/discussions",children:"GitHub Discussions"})]})]})}function h(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(c,{...n})}):c(n)}},8453:function(n,e,i){i.d(e,{R:function(){return r},x:function(){return o}});var t=i(6540);const a={},s=t.createContext(a);function r(n){const e=t.useContext(s);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function o(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:r(n.components),t.createElement(s.Provider,{value:e},n.children)}}}]);