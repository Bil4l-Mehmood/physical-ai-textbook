"use strict";(self.webpackChunkphysical_ai_textbook=self.webpackChunkphysical_ai_textbook||[]).push([[53],{3087:function(n,e,r){r.r(e),r.d(e,{assets:function(){return l},contentTitle:function(){return o},default:function(){return h},frontMatter:function(){return s},metadata:function(){return i},toc:function(){return d}});var i=JSON.parse('{"id":"chapter-3/3-1-isaac-sim-basics","title":"NVIDIA Isaac Sim: Photorealistic Simulation and Synthetic Data Generation","description":"Master photorealistic robot simulation and generate synthetic training data with NVIDIA Isaac Sim","source":"@site/docs/chapter-3/3-1-isaac-sim-basics.md","sourceDirName":"chapter-3","slug":"/chapter-3/3-1-isaac-sim-basics","permalink":"/physical-ai-textbook/docs/chapter-3/3-1-isaac-sim-basics","draft":false,"unlisted":false,"editUrl":"https://github.com/Bil4l-Mehmood/physical-ai-textbook/edit/main/docs/chapter-3/3-1-isaac-sim-basics.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"sidebar_label":"Lesson 3.1: NVIDIA Isaac Sim","title":"NVIDIA Isaac Sim: Photorealistic Simulation and Synthetic Data Generation","description":"Master photorealistic robot simulation and generate synthetic training data with NVIDIA Isaac Sim","duration":120,"difficulty":"Advanced","hardware":["Ubuntu 22.04 LTS","NVIDIA GPU RTX 4070+ (12GB VRAM min)","ROS 2 Humble","NVIDIA Isaac Sim 4.0+"],"prerequisites":["Lesson 2.3: Sensor Simulation & Unity Integration"]},"sidebar":"tutorialSidebar","previous":{"title":"Lesson 2.3: Sensors & Unity","permalink":"/physical-ai-textbook/docs/chapter-2/2-3-sensors-unity"},"next":{"title":"Lesson 3.2: VSLAM & Navigation","permalink":"/physical-ai-textbook/docs/chapter-3/3-2-vslam-navigation"}}'),t=r(4848),a=r(8453);const s={sidebar_position:1,sidebar_label:"Lesson 3.1: NVIDIA Isaac Sim",title:"NVIDIA Isaac Sim: Photorealistic Simulation and Synthetic Data Generation",description:"Master photorealistic robot simulation and generate synthetic training data with NVIDIA Isaac Sim",duration:120,difficulty:"Advanced",hardware:["Ubuntu 22.04 LTS","NVIDIA GPU RTX 4070+ (12GB VRAM min)","ROS 2 Humble","NVIDIA Isaac Sim 4.0+"],prerequisites:["Lesson 2.3: Sensor Simulation & Unity Integration"]},o="Lesson 3.1: NVIDIA Isaac Sim - Photorealistic Robot Simulation",l={},d=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Hardware Requirements",id:"hardware-requirements",level:2},{value:"Minimum Specifications",id:"minimum-specifications",level:3},{value:"Hardware Alternatives",id:"hardware-alternatives",level:3},{value:"Part 1: NVIDIA Isaac Ecosystem Overview",id:"part-1-nvidia-isaac-ecosystem-overview",level:2},{value:"Isaac Components",id:"isaac-components",level:3},{value:"Why NVIDIA Isaac for Physical AI",id:"why-nvidia-isaac-for-physical-ai",level:3},{value:"Part 2: Installation &amp; Setup",id:"part-2-installation--setup",level:2},{value:"Step 1: System Verification",id:"step-1-system-verification",level:3},{value:"Step 2: Download Isaac Sim",id:"step-2-download-isaac-sim",level:3},{value:"Step 3: Verify Installation",id:"step-3-verify-installation",level:3},{value:"Step 4: Configure ROS 2 Integration",id:"step-4-configure-ros-2-integration",level:3},{value:"Part 3: Core Concepts - USD and PhysX",id:"part-3-core-concepts---usd-and-physx",level:2},{value:"Universal Scene Description (USD)",id:"universal-scene-description-usd",level:3},{value:"PhysX Physics Engine",id:"physx-physics-engine",level:3},{value:"Part 4: Creating a Simulation Environment",id:"part-4-creating-a-simulation-environment",level:2},{value:"Method 1: Using UI (Visual Building)",id:"method-1-using-ui-visual-building",level:3},{value:"Method 2: Python Scripting (Programmatic)",id:"method-2-python-scripting-programmatic",level:3},{value:"Part 5: Synthetic Data Generation for Training",id:"part-5-synthetic-data-generation-for-training",level:2},{value:"Generating Annotated Training Data",id:"generating-annotated-training-data",level:3},{value:"Part 6: ROS 2 Integration",id:"part-6-ros-2-integration",level:2},{value:"Controlling Isaac Sim Robot from ROS 2",id:"controlling-isaac-sim-robot-from-ros-2",level:3},{value:"Hands-On Exercise",id:"hands-on-exercise",level:2},{value:"Step 1: Create Isaac Sim Project",id:"step-1-create-isaac-sim-project",level:3},{value:"Step 2: Generate Synthetic Data",id:"step-2-generate-synthetic-data",level:3},{value:"Step 3: Control with ROS 2",id:"step-3-control-with-ros-2",level:3},{value:"Exercises",id:"exercises",level:3},{value:"Common Issues &amp; Troubleshooting",id:"common-issues--troubleshooting",level:2},{value:"Key Takeaways",id:"key-takeaways",level:2},{value:"Further Reading",id:"further-reading",level:2}];function c(n){const e={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.header,{children:(0,t.jsx)(e.h1,{id:"lesson-31-nvidia-isaac-sim---photorealistic-robot-simulation",children:"Lesson 3.1: NVIDIA Isaac Sim - Photorealistic Robot Simulation"})}),"\n",(0,t.jsxs)(e.admonition,{title:"Lesson Overview",type:"info",children:[(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Duration"}),": 120 minutes | ",(0,t.jsx)(e.strong,{children:"Difficulty"}),": Advanced | ",(0,t.jsx)(e.strong,{children:"Hardware"}),": Ubuntu 22.04 + NVIDIA RTX GPU + Isaac Sim"]}),(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Prerequisites"}),": Chapter 1-2 complete (ROS 2, Gazebo, sensors)"]}),(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Learning Outcome"}),": Master photorealistic simulation, synthetic data generation, and sim-to-real transfer with NVIDIA Isaac Sim"]})]}),"\n",(0,t.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsx)(e.p,{children:"By the end of this lesson, you will be able to:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Understand NVIDIA Isaac ecosystem architecture"}),"\n",(0,t.jsx)(e.li,{children:"Set up Isaac Sim on NVIDIA hardware"}),"\n",(0,t.jsx)(e.li,{children:"Create photorealistic environments using Universal Scene Description (USD)"}),"\n",(0,t.jsx)(e.li,{children:"Simulate robots with accurate physics and rendering"}),"\n",(0,t.jsx)(e.li,{children:"Generate synthetic training data for machine learning"}),"\n",(0,t.jsx)(e.li,{children:"Configure domain randomization for sim-to-real transfer"}),"\n",(0,t.jsx)(e.li,{children:"Integrate Isaac Sim with ROS 2 for robot control"}),"\n",(0,t.jsx)(e.li,{children:"Optimize simulation performance for real-time control"}),"\n",(0,t.jsx)(e.li,{children:"Deploy trained models to real robots"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"hardware-requirements",children:"Hardware Requirements"}),"\n",(0,t.jsxs)(e.admonition,{title:"Hardware Demanding",type:"warning",children:[(0,t.jsx)(e.p,{children:"Isaac Sim requires industrial-grade GPU hardware due to:"}),(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Photorealistic rendering"}),": Ray tracing requires RTX (NVIDIA's ray-tracing cores)"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Physics simulation"}),": Complex dynamics with multiple robots"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Synthetic data generation"}),": High-resolution images at 100+ FPS"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Machine learning"}),": Training perception models simultaneously"]}),"\n"]})]}),"\n",(0,t.jsx)(e.h3,{id:"minimum-specifications",children:"Minimum Specifications"}),"\n",(0,t.jsxs)(e.table,{children:[(0,t.jsx)(e.thead,{children:(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.th,{children:"Component"}),(0,t.jsx)(e.th,{children:"Requirement"}),(0,t.jsx)(e.th,{children:"Rationale"})]})}),(0,t.jsxs)(e.tbody,{children:[(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{children:(0,t.jsx)(e.strong,{children:"GPU"})}),(0,t.jsx)(e.td,{children:"NVIDIA RTX 4070 (12GB) or better"}),(0,t.jsx)(e.td,{children:"Ray tracing + simulation"})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{children:(0,t.jsx)(e.strong,{children:"VRAM"})}),(0,t.jsx)(e.td,{children:"12 GB minimum (24 GB recommended)"}),(0,t.jsx)(e.td,{children:"USD asset loading, training models"})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{children:(0,t.jsx)(e.strong,{children:"CPU"})}),(0,t.jsx)(e.td,{children:"Intel i7-13th Gen or AMD Ryzen 9"}),(0,t.jsx)(e.td,{children:"Physics calculations, parallel inference"})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{children:(0,t.jsx)(e.strong,{children:"RAM"})}),(0,t.jsx)(e.td,{children:"64 GB DDR5"}),(0,t.jsx)(e.td,{children:"Multiple environments, data generation"})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{children:(0,t.jsx)(e.strong,{children:"Storage"})}),(0,t.jsx)(e.td,{children:"500 GB NVMe SSD"}),(0,t.jsx)(e.td,{children:"Isaac Sim installation + datasets"})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{children:(0,t.jsx)(e.strong,{children:"OS"})}),(0,t.jsx)(e.td,{children:"Ubuntu 22.04 LTS"}),(0,t.jsx)(e.td,{children:"Official support, ROS 2 Humble compatibility"})]})]})]}),"\n",(0,t.jsx)(e.h3,{id:"hardware-alternatives",children:"Hardware Alternatives"}),"\n",(0,t.jsx)(e.p,{children:(0,t.jsx)(e.strong,{children:"Option A: Local Workstation (Recommended)"})}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Highest performance, lowest latency"}),"\n",(0,t.jsx)(e.li,{children:"Can iterate quickly during development"}),"\n",(0,t.jsx)(e.li,{children:"Ideal for sim-to-real transfer training"}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:(0,t.jsx)(e.strong,{children:"Option B: Cloud GPU Instances"})}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{children:"AWS g5.2xlarge (A10G GPU, 24GB)\r\n\u251c\u2500 Training: $1.50/hour\r\n\u251c\u2500 Total per quarter: ~$205 (120 hours)\r\n\u2514\u2500 Plus data storage: $25/month\n"})}),"\n",(0,t.jsx)(e.p,{children:(0,t.jsx)(e.strong,{children:"Option C: NVIDIA Omniverse Cloud"})}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Native NVIDIA infrastructure"}),"\n",(0,t.jsx)(e.li,{children:"Optimized for Isaac Sim"}),"\n",(0,t.jsx)(e.li,{children:"Seamless ROS 2 integration"}),"\n",(0,t.jsx)(e.li,{children:"Cost: ~$3,000/quarter for power users"}),"\n"]}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"part-1-nvidia-isaac-ecosystem-overview",children:"Part 1: NVIDIA Isaac Ecosystem Overview"}),"\n",(0,t.jsx)(e.h3,{id:"isaac-components",children:"Isaac Components"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Isaac Sim"})," (This lesson)"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Photorealistic 3D environment"}),"\n",(0,t.jsx)(e.li,{children:"Physics simulation with Nvidia PhysX"}),"\n",(0,t.jsx)(e.li,{children:"Synthetic data generation"}),"\n",(0,t.jsx)(e.li,{children:"Domain randomization"}),"\n",(0,t.jsx)(e.li,{children:"Ray-tracing visualization"}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Isaac ROS"})," (Lesson 3.2)"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Hardware-accelerated perception pipeline"}),"\n",(0,t.jsx)(e.li,{children:"VSLAM (Visual Simultaneous Localization and Mapping)"}),"\n",(0,t.jsx)(e.li,{children:"Navigation stack"}),"\n",(0,t.jsx)(e.li,{children:"Computer vision processing"}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Isaac SDK"})," (Advanced - not covered)"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Development toolkit"}),"\n",(0,t.jsx)(e.li,{children:"Custom perception nodes"}),"\n",(0,t.jsx)(e.li,{children:"Reinforcement learning training"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"why-nvidia-isaac-for-physical-ai",children:"Why NVIDIA Isaac for Physical AI"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{children:"Traditional Pipeline           \u2192  NVIDIA Isaac Pipeline\r\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n\u2502Real Robots  \u2502  (Expensive)    \u2502Photorealistic Sim\u2502\r\n\u2502  Sensors    \u2502  (Slow)          \u2502Synthetic Data    \u2502\r\n\u2502Data Collect \u2502  (Dangerous)     \u2502Domain Random     \u2502\r\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n      \u2193                                 \u2193\r\n Manual Labels                    Automated Generation\r\n      \u2193                                 \u2193\r\n ML Training  (Weeks)            ML Training (Days)\r\n      \u2193                                 \u2193\r\n Real Robot   (1-2x)             Sim-to-Real (90%+ success)\n"})}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Benefits"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Generate 1M images in 24 hours (vs weeks on real robots)"}),"\n",(0,t.jsx)(e.li,{children:"Perfect ground truth annotations (auto-generated)"}),"\n",(0,t.jsx)(e.li,{children:"Infinitely variable conditions (no manual diversity)"}),"\n",(0,t.jsx)(e.li,{children:"Zero robot wear/damage during training"}),"\n",(0,t.jsx)(e.li,{children:"10-100x faster iteration cycle"}),"\n"]}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"part-2-installation--setup",children:"Part 2: Installation & Setup"}),"\n",(0,t.jsx)(e.h3,{id:"step-1-system-verification",children:"Step 1: System Verification"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:'# Check GPU\r\nnvidia-smi\r\n# Should show: NVIDIA RTX 4070/4080/4090 or A10G\r\n\r\n# Verify NVIDIA drivers (should be 525+)\r\nnvidia-smi | grep "Driver Version"\r\n\r\n# Check disk space for Isaac installation\r\ndf -h /\r\n# Need: 100GB free for Isaac Sim + datasets\r\n\r\n# Verify Ubuntu version\r\nlsb_release -d\r\n# Should be: Ubuntu 22.04 LTS\n'})}),"\n",(0,t.jsx)(e.h3,{id:"step-2-download-isaac-sim",children:"Step 2: Download Isaac Sim"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:'# Create installation directory\r\nmkdir -p ~/nvidia_omniverse\r\ncd ~/nvidia_omniverse\r\n\r\n# Option A: Download from NVIDIA Launcher\r\n# 1. Go to https://www.nvidia.com/en-us/omniverse/\r\n# 2. Download "Omniverse Launcher"\r\n# 3. Install and log in\r\n# 4. Install "Isaac Sim" from launcher\r\n\r\n# Option B: Command-line installation (requires auth)\r\n# NVIDIA_TOKEN=your_token ./isaac_sim_installer.sh\n'})}),"\n",(0,t.jsx)(e.h3,{id:"step-3-verify-installation",children:"Step 3: Verify Installation"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"# Launch Isaac Sim\r\n~/nvidia_omniverse/isaac_sim/isaac_sim.sh\r\n\r\n# Expected: Omniverse Isaac Sim window opens\r\n# Shows default scene with robot(s)\n"})}),"\n",(0,t.jsx)(e.h3,{id:"step-4-configure-ros-2-integration",children:"Step 4: Configure ROS 2 Integration"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:'# Inside Isaac Sim, install ROS 2 Bridge\r\n# Extensions \u2192 Search "ROS2"\r\n# Enable: "ROS2 Bridge" extension\r\n\r\n# Verify ROS 2 topics available\r\nsource /opt/ros/humble/setup.bash\r\nros2 topic list\r\n# Should show Isaac-generated topics\n'})}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"part-3-core-concepts---usd-and-physx",children:"Part 3: Core Concepts - USD and PhysX"}),"\n",(0,t.jsx)(e.h3,{id:"universal-scene-description-usd",children:"Universal Scene Description (USD)"}),"\n",(0,t.jsx)(e.p,{children:"USD is the 3D format used by Isaac Sim (and industry standard):"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'# Simple USD robot description\r\n#usda 1.0\r\n(\r\n    defaultPrim = "World"\r\n)\r\n\r\ndef Xform "World"\r\n{\r\n    def Mesh "base_link"\r\n    {\r\n        # Visual geometry\r\n        int[] faceVertexCounts = [4, 4, 4, 4, 4, 4]\r\n        int[] faceVertexIndices = [...]\r\n        point3f[] points = [...]\r\n\r\n        # Physics material\r\n        rel material:binding = </Materials/Plastic>\r\n    }\r\n\r\n    def Mesh "link_1"\r\n    {\r\n        # Joint transform\r\n        matrix4d xformOp:transform = (...)\r\n\r\n        # Collision geometry\r\n        custom bool physics:enabled = true\r\n        custom float physics:mass = 0.5\r\n    }\r\n}\n'})}),"\n",(0,t.jsx)(e.h3,{id:"physx-physics-engine",children:"PhysX Physics Engine"}),"\n",(0,t.jsx)(e.p,{children:"NVIDIA's proprietary physics engine (used in Isaac Sim):"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Advantages over ODE/Bullet"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"GPU-accelerated calculations"}),"\n",(0,t.jsx)(e.li,{children:"Better humanoid dynamics"}),"\n",(0,t.jsx)(e.li,{children:"Deterministic simulation"}),"\n",(0,t.jsx)(e.li,{children:"Cloth and soft body support"}),"\n",(0,t.jsx)(e.li,{children:"More realistic contact/friction"}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Configuration in USD"}),":"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'def Xform "Physics"\r\n{\r\n    # Time stepping\r\n    float timeCodesPerSecond = 30.0\r\n\r\n    # Gravity\r\n    vector3f gravity = (0, 0, -9.81)\r\n\r\n    # Solver\r\n    uint solverType = 1  # TGS solver (1) or PGS (0)\r\n    uint broadphaseType = 0\r\n    uint narrowphaseType = 1\r\n    uint constraintType = 2\r\n}\n'})}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"part-4-creating-a-simulation-environment",children:"Part 4: Creating a Simulation Environment"}),"\n",(0,t.jsx)(e.h3,{id:"method-1-using-ui-visual-building",children:"Method 1: Using UI (Visual Building)"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{children:'1. Launch Isaac Sim\r\n2. File \u2192 New \u2192 Empty Stage\r\n3. Layout \u2192 Change to "Perspective" view\r\n4. Add Ground Plane:\r\n   - Create \u2192 Mesh \u2192 Ground Plane\r\n5. Add Robot:\r\n   - File \u2192 Open \u2192 your_robot.usd\r\n6. Add Lights:\r\n   - Create \u2192 Light \u2192 Sphere\r\n   - Create \u2192 Light \u2192 Directional (sun)\r\n7. Configure Physics:\r\n   - Window \u2192 Physics\r\n   - Set gravity, solver type\r\n8. Save As: my_world.usd\n'})}),"\n",(0,t.jsx)(e.h3,{id:"method-2-python-scripting-programmatic",children:"Method 2: Python Scripting (Programmatic)"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\r\n"""\r\nCreate Isaac Sim environment programmatically\r\n"""\r\n\r\nimport omni.kit.app\r\nfrom omni.isaac.core import World\r\nfrom omni.isaac.core.utils.stage import create_new_stage\r\nfrom omni.isaac.core.utils.prims import delete_prim\r\nfrom omni.isaac.core.physics_context import PhysicsContext\r\nfrom omni.isaac.core.robots import Robot\r\nfrom pxr import Usd, UsdGeom\r\n\r\n\r\ndef create_simulation_world():\r\n    """\r\n    Create a complete Isaac Sim environment with:\r\n    - Ground plane\r\n    - Lighting\r\n    - Physics configuration\r\n    - Robot model\r\n    """\r\n\r\n    # Initialize stage\r\n    create_new_stage()\r\n    stage = omni.usd.get_context().get_stage()\r\n\r\n    # Create world\r\n    world = World(stage=stage)\r\n    world.scene.add_ground_plane()\r\n\r\n    # Configure physics\r\n    physics_context = PhysicsContext(\r\n        stage=stage,\r\n        physics_dt=1.0/60.0,  # 60 Hz simulation\r\n        rendering_dt=1.0/30.0,  # 30 Hz rendering\r\n        gravity=(0, 0, -9.81),\r\n        solver_type="TGS"  # NVIDIA TGS solver\r\n    )\r\n\r\n    # Add lighting\r\n    stage.DefinePrim("/World/Lighting/sun", "Xform")\r\n    light = UsdGeom.Sphere.Define(stage, "/World/Lighting/sun")\r\n    light.GetRadiusAttr().Set(1)\r\n\r\n    # Load robot\r\n    robot_usd_path = "/home/user/robots/humanoid.usd"\r\n    stage.DefinePrim("/World/robot", "Xform").GetReferences().AddReference(robot_usd_path)\r\n\r\n    # Set robot pose\r\n    stage.GetPrimAtPath("/World/robot").GetAttribute("xformOp:translate").Set((0, 0, 1))\r\n\r\n    # Save stage\r\n    stage.Export("/home/user/my_simulation.usd")\r\n\r\n    print("\u2705 Simulation environment created")\r\n\r\n\r\nif __name__ == "__main__":\r\n    create_simulation_world()\n'})}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"part-5-synthetic-data-generation-for-training",children:"Part 5: Synthetic Data Generation for Training"}),"\n",(0,t.jsx)(e.h3,{id:"generating-annotated-training-data",children:"Generating Annotated Training Data"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\r\n"""\r\nGenerate synthetic training dataset with automatic annotations\r\n"""\r\n\r\nimport omni.kit.app\r\nimport numpy as np\r\nfrom PIL import Image\r\nimport json\r\nimport os\r\n\r\n\r\nclass SyntheticDataGenerator:\r\n    """Generate annotated synthetic data for ML training"""\r\n\r\n    def __init__(self, output_dir="/tmp/synthetic_data"):\r\n        self.output_dir = output_dir\r\n        self.image_dir = os.path.join(output_dir, "images")\r\n        self.labels_dir = os.path.join(output_dir, "labels")\r\n        self.metadata_dir = os.path.join(output_dir, "metadata")\r\n\r\n        # Create directories\r\n        os.makedirs(self.image_dir, exist_ok=True)\r\n        os.makedirs(self.labels_dir, exist_ok=True)\r\n        os.makedirs(self.metadata_dir, exist_ok=True)\r\n\r\n    def randomize_domain(self, iteration):\r\n        """\r\n        Apply domain randomization to make sim-to-real transfer effective:\r\n        - Vary lighting conditions\r\n        - Change material properties\r\n        - Randomize object positions\r\n        - Add camera noise\r\n        """\r\n\r\n        # Lighting variation\r\n        light_intensity = np.random.uniform(0.5, 2.0)\r\n        light_color = np.random.uniform([0.5, 0.5, 0.5], [1.0, 1.0, 1.0])\r\n        # Apply to Isaac Sim light\r\n\r\n        # Texture variation (metallic, roughness, color)\r\n        material_properties = {\r\n            "metallic": np.random.uniform(0.0, 1.0),\r\n            "roughness": np.random.uniform(0.1, 0.9),\r\n            "color": {\r\n                "r": np.random.uniform(0.2, 1.0),\r\n                "g": np.random.uniform(0.2, 1.0),\r\n                "b": np.random.uniform(0.2, 1.0)\r\n            }\r\n        }\r\n\r\n        # Object pose randomization\r\n        poses = {\r\n            "robot_x": np.random.uniform(-2, 2),\r\n            "robot_y": np.random.uniform(-2, 2),\r\n            "robot_z": 0.5,\r\n            "camera_angle": np.random.uniform(-30, 30)  # degrees\r\n        }\r\n\r\n        # Camera noise (Gaussian noise in image)\r\n        camera_noise = np.random.normal(0, 5, (480, 640, 3))\r\n\r\n        return {\r\n            "iteration": iteration,\r\n            "lighting": {\r\n                "intensity": light_intensity,\r\n                "color": light_color.tolist()\r\n            },\r\n            "materials": material_properties,\r\n            "poses": poses,\r\n            "camera_noise_stddev": 5.0\r\n        }\r\n\r\n    def generate_frame(self, iteration, rgb_image, depth_image, segmentation):\r\n        """\r\n        Save frame with automatic annotations\r\n        """\r\n\r\n        # Save RGB image\r\n        image_filename = f"frame_{iteration:06d}.png"\r\n        image_path = os.path.join(self.image_dir, image_filename)\r\n        Image.fromarray(rgb_image).save(image_path)\r\n\r\n        # Save depth image (as 16-bit grayscale)\r\n        depth_filename = f"depth_{iteration:06d}.png"\r\n        depth_path = os.path.join(self.image_dir, depth_filename)\r\n        depth_normalized = (depth_image / depth_image.max() * 65535).astype(np.uint16)\r\n        Image.fromarray(depth_normalized).save(depth_path)\r\n\r\n        # Save segmentation mask\r\n        seg_filename = f"segmentation_{iteration:06d}.png"\r\n        seg_path = os.path.join(self.image_dir, seg_filename)\r\n        Image.fromarray(segmentation).save(seg_path)\r\n\r\n        # Save annotations as JSON\r\n        randomization = self.randomize_domain(iteration)\r\n        annotations = {\r\n            "image_id": iteration,\r\n            "image_file": image_filename,\r\n            "depth_file": depth_filename,\r\n            "segmentation_file": seg_filename,\r\n            "width": 640,\r\n            "height": 480,\r\n            "camera_fx": 554.254,  # Intrinsics\r\n            "camera_fy": 554.254,\r\n            "camera_cx": 320.0,\r\n            "camera_cy": 240.0,\r\n            "objects": [\r\n                {\r\n                    "id": 1,\r\n                    "name": "robot",\r\n                    "bbox": [100, 100, 200, 300],  # x, y, width, height\r\n                    "segmentation_id": 1,\r\n                    "pose": {\r\n                        "x": randomization["poses"]["robot_x"],\r\n                        "y": randomization["poses"]["robot_y"],\r\n                        "z": randomization["poses"]["robot_z"]\r\n                    }\r\n                }\r\n            ],\r\n            "randomization": randomization\r\n        }\r\n\r\n        # Save JSON annotation\r\n        label_filename = f"frame_{iteration:06d}.json"\r\n        label_path = os.path.join(self.labels_dir, label_filename)\r\n        with open(label_path, \'w\') as f:\r\n            json.dump(annotations, f, indent=2)\r\n\r\n        return image_path, label_path\r\n\r\n    def generate_dataset(self, num_frames=1000):\r\n        """Generate complete training dataset"""\r\n\r\n        for frame_idx in range(num_frames):\r\n            # Simulate rendering (in real code, capture from Isaac Sim)\r\n            rgb = np.random.randint(0, 256, (480, 640, 3), dtype=np.uint8)\r\n            depth = np.random.uniform(0.1, 10.0, (480, 640)).astype(np.float32)\r\n            seg = np.random.randint(0, 10, (480, 640), dtype=np.uint8)\r\n\r\n            self.generate_frame(frame_idx, rgb, depth, seg)\r\n\r\n            if frame_idx % 100 == 0:\r\n                print(f"\u2705 Generated {frame_idx}/{num_frames} frames")\r\n\r\n        # Create dataset manifest\r\n        manifest = {\r\n            "total_frames": num_frames,\r\n            "output_directory": self.output_dir,\r\n            "format": "COCO",\r\n            "image_size": [640, 480],\r\n            "camera_model": "pinhole"\r\n        }\r\n\r\n        with open(os.path.join(self.metadata_dir, "manifest.json"), \'w\') as f:\r\n            json.dump(manifest, f, indent=2)\r\n\r\n        print(f"\u2705 Dataset complete: {num_frames} frames in {self.output_dir}")\r\n\r\n\r\nif __name__ == "__main__":\r\n    generator = SyntheticDataGenerator("/tmp/synthetic_training_data")\r\n    generator.generate_dataset(num_frames=10000)\n'})}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"part-6-ros-2-integration",children:"Part 6: ROS 2 Integration"}),"\n",(0,t.jsx)(e.h3,{id:"controlling-isaac-sim-robot-from-ros-2",children:"Controlling Isaac Sim Robot from ROS 2"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\r\n"""\r\nControl Isaac Sim robot using ROS 2 joint commands\r\n"""\r\n\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom trajectory_msgs.msg import JointTrajectory, JointTrajectoryPoint\r\nfrom sensor_msgs.msg import JointState\r\nimport math\r\nimport time\r\n\r\n\r\nclass IsaacSimController(Node):\r\n    """Send joint commands to Isaac Sim simulated robot"""\r\n\r\n    def __init__(self):\r\n        super().__init__(\'isaac_sim_controller\')\r\n\r\n        # Publisher for joint trajectory commands\r\n        self.joint_traj_pub = self.create_publisher(\r\n            JointTrajectory,\r\n            \'/isaac_sim/joint_trajectory_controller/commands\',\r\n            10\r\n        )\r\n\r\n        # Subscriber for joint state feedback\r\n        self.joint_state_sub = self.create_subscription(\r\n            JointState,\r\n            \'/isaac_sim/joint_states\',\r\n            self.joint_state_callback,\r\n            10\r\n        )\r\n\r\n        self.current_joint_positions = {}\r\n        self.get_logger().info(\'Isaac Sim controller initialized\')\r\n\r\n    def joint_state_callback(self, msg):\r\n        """Monitor current joint states from simulation"""\r\n        for i, name in enumerate(msg.name):\r\n            self.current_joint_positions[name] = msg.position[i]\r\n\r\n    def send_joint_command(self, joint_targets, duration=1.0):\r\n        """\r\n        Send joint position command to Isaac Sim\r\n\r\n        Args:\r\n            joint_targets: Dict of {joint_name: target_position}\r\n            duration: Time to reach target (seconds)\r\n        """\r\n\r\n        traj = JointTrajectory()\r\n        traj.header.stamp = self.get_clock().now().to_msg()\r\n        traj.joint_names = list(joint_targets.keys())\r\n\r\n        point = JointTrajectoryPoint()\r\n        point.positions = list(joint_targets.values())\r\n        point.time_from_start.sec = int(duration)\r\n        point.time_from_start.nanosec = int((duration % 1) * 1e9)\r\n\r\n        traj.points.append(point)\r\n        self.joint_traj_pub.publish(traj)\r\n\r\n        self.get_logger().info(f\'Sent joint command: {joint_targets}\')\r\n\r\n    def walk_forward(self):\r\n        """Make humanoid walk forward"""\r\n\r\n        # Simplified bipedal walking sequence\r\n        walking_sequence = [\r\n            {"left_hip": 0.0, "right_hip": 0.0},\r\n            {"left_hip": 0.5, "right_hip": -0.5},\r\n            {"left_hip": 0.0, "right_hip": 0.0},\r\n            {"left_hip": -0.5, "right_hip": 0.5},\r\n        ]\r\n\r\n        for pose in walking_sequence:\r\n            self.send_joint_command(pose, duration=0.5)\r\n            time.sleep(0.6)  # Wait for movement to complete\r\n\r\n        self.get_logger().info(\'\u2705 Walking sequence complete\')\r\n\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    controller = IsaacSimController()\r\n\r\n    # Execute walking pattern\r\n    controller.walk_forward()\r\n\r\n    controller.destroy_node()\r\n    rclpy.shutdown()\r\n\r\n\r\nif __name__ == \'__main__\':\r\n    main()\n'})}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"hands-on-exercise",children:"Hands-On Exercise"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Task"}),": Create a photorealistic Isaac Sim environment with a robot, generate synthetic data, and control it with ROS 2."]}),"\n",(0,t.jsx)(e.h3,{id:"step-1-create-isaac-sim-project",children:"Step 1: Create Isaac Sim Project"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"# Launch Isaac Sim\r\n~/nvidia_omniverse/isaac_sim/isaac_sim.sh\r\n\r\n# In the UI:\r\n# 1. File \u2192 New\r\n# 2. Create \u2192 Xform (ground plane)\r\n# 3. File \u2192 Open \u2192 Load your robot.usd\r\n# 4. Configure physics: Physics at top\r\n# 5. Save as: my_robot_world.usd\n"})}),"\n",(0,t.jsx)(e.h3,{id:"step-2-generate-synthetic-data",children:"Step 2: Generate Synthetic Data"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"# Create data generation script\r\ncat > ~/isaac_data_gen.py << 'EOF'\r\n# (Paste SyntheticDataGenerator code from Part 5)\r\nEOF\r\n\r\npython3 ~/isaac_data_gen.py\r\n# Output: 10,000 annotated frames in ~/synthetic_training_data/\n"})}),"\n",(0,t.jsx)(e.h3,{id:"step-3-control-with-ros-2",children:"Step 3: Control with ROS 2"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"# Terminal 1: Isaac Sim\r\n~/nvidia_omniverse/isaac_sim/isaac_sim.sh\r\n\r\n# Terminal 2: ROS 2 controller\r\nsource /opt/ros/humble/setup.bash\r\npython3 ~/isaac_sim_controller.py\n"})}),"\n",(0,t.jsx)(e.h3,{id:"exercises",children:"Exercises"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Domain Randomization"}),": Vary lighting 100 times and save dataset"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Data Annotation"}),": Verify JSON labels match images"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Robot Control"}),": Implement complete walking cycle"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Camera Calibration"}),": Adjust camera intrinsics and compare with real camera"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Reinforcement Learning"}),": Train a simple policy with generated data"]}),"\n"]}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"common-issues--troubleshooting",children:"Common Issues & Troubleshooting"}),"\n",(0,t.jsxs)(e.table,{children:[(0,t.jsx)(e.thead,{children:(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.th,{children:"Issue"}),(0,t.jsx)(e.th,{children:"Cause"}),(0,t.jsx)(e.th,{children:"Solution"})]})}),(0,t.jsxs)(e.tbody,{children:[(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{children:"Isaac Sim won't launch"}),(0,t.jsx)(e.td,{children:"GPU driver outdated"}),(0,t.jsx)(e.td,{children:"Update NVIDIA drivers to 525+"})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{children:"Low FPS (<20)"}),(0,t.jsx)(e.td,{children:"Simulation too complex"}),(0,t.jsx)(e.td,{children:"Reduce object count, use simpler meshes"})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{children:"ROS 2 topics empty"}),(0,t.jsx)(e.td,{children:"Bridge not enabled"}),(0,t.jsx)(e.td,{children:'Extension \u2192 Enable "ROS2 Bridge"'})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{children:"Synthetic data blurry"}),(0,t.jsx)(e.td,{children:"Rendering resolution low"}),(0,t.jsx)(e.td,{children:"Physics \u2192 Rendering DPI scale 2.0"})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{children:"Physics unstable"}),(0,t.jsx)(e.td,{children:"Solver type wrong"}),(0,t.jsx)(e.td,{children:"Use TGS (type 1) instead of PGS"})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{children:"Memory errors"}),(0,t.jsx)(e.td,{children:"VRAM exhausted"}),(0,t.jsx)(e.td,{children:"Reduce image resolution, use fewer environments"})]})]})]}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,t.jsxs)(e.p,{children:["\u2705 ",(0,t.jsx)(e.strong,{children:"Isaac Ecosystem"}),": Simulation (Isaac Sim) + Perception (Isaac ROS) + Training"]}),"\n",(0,t.jsxs)(e.p,{children:["\u2705 ",(0,t.jsx)(e.strong,{children:"Photorealistic Rendering"}),": Ray tracing for sim-to-real transfer effectiveness"]}),"\n",(0,t.jsxs)(e.p,{children:["\u2705 ",(0,t.jsx)(e.strong,{children:"Synthetic Data"}),": Generate 1M annotated frames in hours, not weeks"]}),"\n",(0,t.jsxs)(e.p,{children:["\u2705 ",(0,t.jsx)(e.strong,{children:"Domain Randomization"}),": Vary lighting/materials/poses to bridge sim-to-real gap"]}),"\n",(0,t.jsxs)(e.p,{children:["\u2705 ",(0,t.jsx)(e.strong,{children:"ROS 2 Native"}),": Direct integration with ROS 2 control stacks"]}),"\n",(0,t.jsxs)(e.p,{children:["\u2705 ",(0,t.jsx)(e.strong,{children:"Hardware Demanding"}),": RTX 4070+ GPU required for real-time simulation"]}),"\n",(0,t.jsxs)(e.p,{children:["\u2705 ",(0,t.jsx)(e.strong,{children:"GPU Physics"}),": NVIDIA PhysX enables accurate humanoid dynamics"]}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"further-reading",children:"Further Reading"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:["\ud83d\udcd6 ",(0,t.jsx)(e.a,{href:"https://docs.omniverse.nvidia.com/isaacsim/latest/",children:"NVIDIA Isaac Sim Documentation"})]}),"\n",(0,t.jsxs)(e.li,{children:["\ud83d\udcd6 ",(0,t.jsx)(e.a,{href:"https://graphics.pixar.com/usd/docs/index.html",children:"USD Specification"})]}),"\n",(0,t.jsxs)(e.li,{children:["\ud83d\udcd6 ",(0,t.jsx)(e.a,{href:"https://nvlabs.github.io/sim-to-real-robotics/",children:"Sim-to-Real Transfer Guide"})]}),"\n",(0,t.jsxs)(e.li,{children:["\ud83d\udcd6 ",(0,t.jsx)(e.a,{href:"https://arxiv.org/abs/1703.06907",children:"Domain Randomization Paper"})]}),"\n"]}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Next Lesson"}),": ",(0,t.jsx)(e.a,{href:"/physical-ai-textbook/docs/chapter-3/3-2-vslam-navigation",children:"Lesson 3.2: VSLAM & Navigation with Isaac ROS"})]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Questions?"})," See ",(0,t.jsx)(e.a,{href:"/physical-ai-textbook/docs/faq",children:"FAQ"})," or ",(0,t.jsx)(e.a,{href:"https://github.com/physical-ai-course/physical-ai-textbook/discussions",children:"GitHub Discussions"})]})]})}function h(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(c,{...n})}):c(n)}},8453:function(n,e,r){r.d(e,{R:function(){return s},x:function(){return o}});var i=r(6540);const t={},a=i.createContext(t);function s(n){const e=i.useContext(a);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function o(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:s(n.components),i.createElement(a.Provider,{value:e},n.children)}}}]);