"use strict";(self.webpackChunkphysical_ai_textbook=self.webpackChunkphysical_ai_textbook||[]).push([[702],{8453:function(n,e,a){a.d(e,{R:function(){return o},x:function(){return t}});var s=a(6540);const i={},r=s.createContext(i);function o(n){const e=s.useContext(r);return s.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function t(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(i):n.components||i:o(n.components),s.createElement(r.Provider,{value:e},n.children)}},9378:function(n,e,a){a.r(e),a.d(e,{assets:function(){return l},contentTitle:function(){return t},default:function(){return u},frontMatter:function(){return o},metadata:function(){return s},toc:function(){return c}});var s=JSON.parse('{"id":"chapter-3/3-2-vslam-navigation","title":"Isaac ROS: Hardware-Accelerated VSLAM and Autonomous Navigation","description":"Implement visual SLAM and autonomous navigation using Isaac ROS and Nav2","source":"@site/docs/chapter-3/3-2-vslam-navigation.md","sourceDirName":"chapter-3","slug":"/chapter-3/3-2-vslam-navigation","permalink":"/physical-ai-textbook/docs/chapter-3/3-2-vslam-navigation","draft":false,"unlisted":false,"editUrl":"https://github.com/Bil4l-Mehmood/physical-ai-textbook/edit/main/docs/chapter-3/3-2-vslam-navigation.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"sidebar_label":"Lesson 3.2: VSLAM & Navigation","title":"Isaac ROS: Hardware-Accelerated VSLAM and Autonomous Navigation","description":"Implement visual SLAM and autonomous navigation using Isaac ROS and Nav2","duration":120,"difficulty":"Advanced","hardware":["Ubuntu 22.04 LTS","Jetson Orin Nano/NX","Intel RealSense D435i","ROS 2 Humble"],"prerequisites":["Lesson 3.1: NVIDIA Isaac Sim Basics"]},"sidebar":"tutorialSidebar","previous":{"title":"Lesson 3.1: NVIDIA Isaac Sim","permalink":"/physical-ai-textbook/docs/chapter-3/3-1-isaac-sim-basics"},"next":{"title":"Lesson 3.3: Computer Vision Isaac ROS","permalink":"/physical-ai-textbook/docs/chapter-3/3-3-computer-vision-isaac-ros"}}'),i=a(4848),r=a(8453);const o={sidebar_position:2,sidebar_label:"Lesson 3.2: VSLAM & Navigation",title:"Isaac ROS: Hardware-Accelerated VSLAM and Autonomous Navigation",description:"Implement visual SLAM and autonomous navigation using Isaac ROS and Nav2",duration:120,difficulty:"Advanced",hardware:["Ubuntu 22.04 LTS","Jetson Orin Nano/NX","Intel RealSense D435i","ROS 2 Humble"],prerequisites:["Lesson 3.1: NVIDIA Isaac Sim Basics"]},t="Lesson 3.2: VSLAM & Navigation with Isaac ROS",l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Part 1: VSLAM Fundamentals",id:"part-1-vslam-fundamentals",level:2},{value:"SLAM vs Pure Localization",id:"slam-vs-pure-localization",level:3},{value:"Isaac ROS vs Standard ROS 2 SLAM",id:"isaac-ros-vs-standard-ros-2-slam",level:3},{value:"Visual Features for SLAM",id:"visual-features-for-slam",level:3},{value:"Part 2: Installing Isaac ROS VSLAM",id:"part-2-installing-isaac-ros-vslam",level:2},{value:"Prerequisites Check",id:"prerequisites-check",level:3},{value:"Installation on Jetson",id:"installation-on-jetson",level:3},{value:"Verification",id:"verification",level:3},{value:"Part 3: SLAM Configuration and Launch",id:"part-3-slam-configuration-and-launch",level:2},{value:"SLAM Configuration File",id:"slam-configuration-file",level:3},{value:"SLAM Launch File",id:"slam-launch-file",level:3},{value:"Launch VSLAM",id:"launch-vslam",level:3},{value:"Part 4: Nav2 Navigation Stack",id:"part-4-nav2-navigation-stack",level:2},{value:"Nav2 Configuration",id:"nav2-configuration",level:3},{value:"Nav2 Launch File",id:"nav2-launch-file",level:3},{value:"Part 5: End-to-End VSLAM + Navigation",id:"part-5-end-to-end-vslam--navigation",level:2},{value:"Complete System Script",id:"complete-system-script",level:3},{value:"Hands-On Exercise",id:"hands-on-exercise",level:2},{value:"Step 1: Launch VSLAM",id:"step-1-launch-vslam",level:3},{value:"Step 2: Map Environment",id:"step-2-map-environment",level:3},{value:"Step 3: Save Map",id:"step-3-save-map",level:3},{value:"Step 4: Launch Navigation",id:"step-4-launch-navigation",level:3},{value:"Step 5: Send Navigation Goals",id:"step-5-send-navigation-goals",level:3},{value:"Exercises",id:"exercises",level:3},{value:"Common Issues &amp; Solutions",id:"common-issues--solutions",level:2},{value:"Key Takeaways",id:"key-takeaways",level:2}];function d(n){const e={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.header,{children:(0,i.jsx)(e.h1,{id:"lesson-32-vslam--navigation-with-isaac-ros",children:"Lesson 3.2: VSLAM & Navigation with Isaac ROS"})}),"\n",(0,i.jsxs)(e.admonition,{title:"Lesson Overview",type:"info",children:[(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Duration"}),": 120 minutes | ",(0,i.jsx)(e.strong,{children:"Difficulty"}),": Advanced | ",(0,i.jsx)(e.strong,{children:"Hardware"}),": Jetson Orin + RealSense + ROS 2 Humble"]}),(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Prerequisites"}),": Lesson 3.1 complete"]}),(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Learning Outcome"}),": Deploy hardware-accelerated VSLAM and autonomous navigation on edge devices"]})]}),"\n",(0,i.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,i.jsx)(e.p,{children:"By the end of this lesson, you will be able to:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Understand Visual SLAM (Simultaneous Localization and Mapping)"}),"\n",(0,i.jsx)(e.li,{children:"Deploy Isaac ROS VSLAM on Jetson hardware"}),"\n",(0,i.jsx)(e.li,{children:"Build real-time occupancy maps from camera and depth data"}),"\n",(0,i.jsx)(e.li,{children:"Use Nav2 for autonomous path planning and navigation"}),"\n",(0,i.jsx)(e.li,{children:"Configure costmaps and planners for humanoid locomotion"}),"\n",(0,i.jsx)(e.li,{children:"Integrate SLAM output with ROS 2 navigation stack"}),"\n",(0,i.jsx)(e.li,{children:"Validate mapping and localization in real environments"}),"\n",(0,i.jsx)(e.li,{children:"Optimize performance on edge devices (Jetson Orin Nano)"}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"part-1-vslam-fundamentals",children:"Part 1: VSLAM Fundamentals"}),"\n",(0,i.jsxs)(e.admonition,{title:"What is VSLAM?",type:"tip",children:[(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Visual SLAM"})," = Computer Vision + Simultaneous Localization and Mapping"]}),(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Localization"}),": Where am I? (uses visual features)"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Mapping"}),": What's around me? (builds environment map)"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Simultaneous"}),": Solves both problems together"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Visual"}),": Uses only camera (RGB-D) as sensor"]}),"\n"]})]}),"\n",(0,i.jsx)(e.h3,{id:"slam-vs-pure-localization",children:"SLAM vs Pure Localization"}),"\n",(0,i.jsxs)(e.table,{children:[(0,i.jsx)(e.thead,{children:(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.th,{children:"Aspect"}),(0,i.jsx)(e.th,{children:"SLAM"}),(0,i.jsx)(e.th,{children:"Localization Only"})]})}),(0,i.jsxs)(e.tbody,{children:[(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:(0,i.jsx)(e.strong,{children:"Map"})}),(0,i.jsx)(e.td,{children:"Builds map while moving"}),(0,i.jsx)(e.td,{children:"Uses pre-existing map"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:(0,i.jsx)(e.strong,{children:"Computational Cost"})}),(0,i.jsx)(e.td,{children:"High (continuous mapping)"}),(0,i.jsx)(e.td,{children:"Lower (matching to map)"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:(0,i.jsx)(e.strong,{children:"Accuracy"})}),(0,i.jsx)(e.td,{children:"Accumulates errors over time"}),(0,i.jsx)(e.td,{children:"Stable with good map"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:(0,i.jsx)(e.strong,{children:"Use Case"})}),(0,i.jsx)(e.td,{children:"Unknown environments"}),(0,i.jsx)(e.td,{children:"Familiar environments"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:(0,i.jsx)(e.strong,{children:"Failure Mode"})}),(0,i.jsx)(e.td,{children:"Loop closure errors"}),(0,i.jsx)(e.td,{children:"Global position loss"})]})]})]}),"\n",(0,i.jsx)(e.h3,{id:"isaac-ros-vs-standard-ros-2-slam",children:"Isaac ROS vs Standard ROS 2 SLAM"}),"\n",(0,i.jsxs)(e.table,{children:[(0,i.jsx)(e.thead,{children:(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.th,{children:"Feature"}),(0,i.jsx)(e.th,{children:"Isaac ROS"}),(0,i.jsx)(e.th,{children:"Standard ROS 2 (gmapping)"})]})}),(0,i.jsxs)(e.tbody,{children:[(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:(0,i.jsx)(e.strong,{children:"Acceleration"})}),(0,i.jsx)(e.td,{children:"GPU-accelerated (RTX cores)"}),(0,i.jsx)(e.td,{children:"CPU only"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:(0,i.jsx)(e.strong,{children:"Latency"})}),(0,i.jsx)(e.td,{children:"<50ms per frame"}),(0,i.jsx)(e.td,{children:"200-500ms per frame"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:(0,i.jsx)(e.strong,{children:"Accuracy"})}),(0,i.jsx)(e.td,{children:"Sub-centimeter"}),(0,i.jsx)(e.td,{children:"Decimeter"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:(0,i.jsx)(e.strong,{children:"Loop Closure"})}),(0,i.jsx)(e.td,{children:"Learned (neural network)"}),(0,i.jsx)(e.td,{children:"Geometric matching"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:(0,i.jsx)(e.strong,{children:"Edge Device"})}),(0,i.jsx)(e.td,{children:"Jetson Orin Nano (40 TOPS)"}),(0,i.jsx)(e.td,{children:"Requires i7+ workstation"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:(0,i.jsx)(e.strong,{children:"Real-time Speed"})}),(0,i.jsx)(e.td,{children:"30 FPS at full resolution"}),(0,i.jsx)(e.td,{children:"5-10 FPS downsample"})]})]})]}),"\n",(0,i.jsx)(e.h3,{id:"visual-features-for-slam",children:"Visual Features for SLAM"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:"RGB Image               ORB Features             Feature Matching\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502             \u2502        \u2502 \u2022 Oriented  \u2502          \u2502 Keypoint 1  \u2502\n\u2502    Robot    \u2502  \u2500\u2500\u2500\u2192  \u2502   FAST      \u2502  \u2500\u2500\u2192     \u2502 matches     \u2502\n\u2502   Camera    \u2502        \u2502 \u2022 Rotation  \u2502          \u2502 Keypoint 2  \u2502\n\u2502             \u2502        \u2502   invariant \u2502          \u2502    in 3D    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502 \u2022 Depth     \u2502          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u2502   clues     \u2502                  \u2193\n                       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                                \u2502 Estimate    \u2502\n                                                \u2502 camera pose \u2502\n                                                \u2502 (SfM)       \u2502\n                                                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"ORB Features"})," (used by Isaac ROS):"]}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"O"}),": Oriented"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"R"}),": FAST corner detector"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"B"}),": BRIEF binary descriptor"]}),"\n",(0,i.jsx)(e.li,{children:"Advantages: Fast (100 FPS), rotation-invariant, GPU-optimizable"}),"\n"]}),"\n",(0,i.jsx)(e.hr,{}),"\n",(0,i.jsx)(e.h2,{id:"part-2-installing-isaac-ros-vslam",children:"Part 2: Installing Isaac ROS VSLAM"}),"\n",(0,i.jsx)(e.h3,{id:"prerequisites-check",children:"Prerequisites Check"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-bash",children:"# Verify Jetson Orin Nano\ncat /etc/nv_tegra_release | head -1\n# Expected: # R35 (release), REVISION: ...\n\n# Verify ROS 2 Humble\nsource /opt/ros/humble/setup.bash\nros2 --version\n\n# Verify RealSense camera\nrealsense-viewer\n# Should show D435i RGB + Depth streams\n"})}),"\n",(0,i.jsx)(e.h3,{id:"installation-on-jetson",children:"Installation on Jetson"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-bash",children:"# Add Isaac ROS sources\nsource /opt/ros/humble/setup.bash\n\n# Install Isaac ROS VSLAM GEMs\nsudo apt update\nsudo apt install -y \\\n  ros-humble-isaac-ros-visual-slam \\\n  ros-humble-isaac-ros-depth-image-proc \\\n  ros-humble-isaac-ros-ess \\\n  ros-humble-realsense2-camera\n\n# Install Nav2 (navigation stack)\nsudo apt install -y \\\n  ros-humble-navigation2 \\\n  ros-humble-nav2-bringup \\\n  ros-humble-cartographer\n"})}),"\n",(0,i.jsx)(e.h3,{id:"verification",children:"Verification"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-bash",children:"# Check Isaac ROS installation\nros2 pkg list | grep isaac_ros\n\n# Expected output:\n# isaac_ros_common\n# isaac_ros_visual_slam\n# isaac_ros_depth_image_proc\n"})}),"\n",(0,i.jsx)(e.hr,{}),"\n",(0,i.jsx)(e.h2,{id:"part-3-slam-configuration-and-launch",children:"Part 3: SLAM Configuration and Launch"}),"\n",(0,i.jsx)(e.h3,{id:"slam-configuration-file",children:"SLAM Configuration File"}),"\n",(0,i.jsxs)(e.p,{children:["Create ",(0,i.jsx)(e.code,{children:"~/ros2_ws/config/visual_slam_config.yaml"}),":"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-yaml",children:"# Isaac ROS Visual SLAM Configuration\nvisual_slam_node:\n  ros__parameters:\n    # Camera calibration (from RealSense D435i)\n    camera_info_topic: '/camera/color/camera_info'\n    rgb_image_topic: '/camera/color/image_raw'\n    depth_image_topic: '/camera/depth/image_rect_raw'\n\n    # Output topics\n    pose_topic: '/visual_slam/pose'\n    odometry_topic: '/visual_slam/odometry'\n    slam_status_topic: '/visual_slam/status'\n\n    # VSLAM parameters\n    enable_depth_regularization: true\n    enable_loop_closure: true\n    enable_loop_closure_visualization: false  # Disable for performance\n\n    # Feature detection\n    min_features_for_tracking: 100\n    max_features_for_tracking: 500\n\n    # Keyframe settings\n    keyframe_translation_threshold: 0.1  # meters\n    keyframe_rotation_threshold: 0.1     # radians\n\n    # Graph optimization\n    loop_closure_confidence_threshold: 0.75\n    optimization_frequency: 10  # Hz\n\n    # Performance tuning for Jetson\n    enable_imu_fusion: false  # Jetson may not have IMU\n    map_update_frequency: 5   # Hz (lower = faster)\n\n    # Output map format\n    map_type: 'occupancy_grid'\n\n    # Debug\n    enable_debug: false\n    verbosity: 'info'\n"})}),"\n",(0,i.jsx)(e.h3,{id:"slam-launch-file",children:"SLAM Launch File"}),"\n",(0,i.jsxs)(e.p,{children:["Create ",(0,i.jsx)(e.code,{children:"~/ros2_ws/launch/visual_slam.launch.py"}),":"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"#!/usr/bin/env python3\n\"\"\"\nLaunch Visual SLAM with RealSense camera on Jetson Orin Nano\n\"\"\"\n\nfrom launch import LaunchDescription\nfrom launch.actions import DeclareLaunchArgument, IncludeLaunchDescription\nfrom launch.substitutions import LaunchConfiguration\nfrom launch.launch_description_sources import PythonLaunchDescriptionSource\nfrom launch_ros.actions import Node, PushRosNamespace\nfrom launch_ros.substitutions import FindPackageShare\nimport os\n\n\ndef generate_launch_description():\n    \"\"\"\n    Launch Visual SLAM with:\n    1. RealSense D435i camera\n    2. Isaac ROS VSLAM node\n    3. RViz visualization\n    \"\"\"\n\n    # Get paths\n    realsense_pkg = FindPackageShare('realsense2_camera')\n    isaac_slam_pkg = FindPackageShare('isaac_ros_visual_slam')\n\n    # Arguments\n    camera_namespace = LaunchConfiguration('camera_namespace', default='camera')\n    use_rviz = LaunchConfiguration('use_rviz', default='true')\n\n    return LaunchDescription([\n        # Launch RealSense camera\n        IncludeLaunchDescription(\n            PythonLaunchDescriptionSource(\n                os.path.join(realsense_pkg, 'launch', 'rs_launch.py')\n            ),\n            launch_arguments={\n                'camera_name': camera_namespace,\n                'depth_module.profile': '640x480x30',  # Jetson-friendly resolution\n                'rgb_camera.color_profile': '640x480x30',\n                'enable_gyro': 'false',\n                'enable_accel': 'false',\n                'align_depth': 'true',\n                'decimation_filter.enable': 'true',  # Reduce computation\n                'spatial_filter.enable': 'true',\n            }.items()\n        ),\n\n        # Isaac ROS Visual SLAM\n        Node(\n            package='isaac_ros_visual_slam',\n            executable='visual_slam_node',\n            namespace='visual_slam',\n            parameters=[{\n                'camera_info_topic': f'/{camera_namespace}/color/camera_info',\n                'rgb_image_topic': f'/{camera_namespace}/color/image_raw',\n                'depth_image_topic': f'/{camera_namespace}/depth/image_rect_raw',\n                'enable_loop_closure': True,\n                'map_type': 'occupancy_grid',\n                'map_publish_rate': 5.0,\n            }],\n            output='screen'\n        ),\n\n        # RViz visualization\n        Node(\n            package='rviz2',\n            executable='rviz2',\n            arguments=['-d', os.path.join(isaac_slam_pkg, 'config', 'visual_slam.rviz')],\n            condition=LaunchConfigurationEquals('use_rviz', 'true'),\n            output='screen'\n        ),\n\n        # TF publisher for base_link \u2192 camera transformation\n        Node(\n            package='tf2_ros',\n            executable='static_transform_publisher',\n            arguments=['0', '0', '0.1', '0', '0', '0', 'base_link', f'{camera_namespace}_link'],\n            output='screen'\n        ),\n    ])\n"})}),"\n",(0,i.jsx)(e.h3,{id:"launch-vslam",children:"Launch VSLAM"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-bash",children:"# Terminal 1: Launch VSLAM\nsource /opt/ros/humble/setup.bash\nros2 launch ~/ros2_ws/launch/visual_slam.launch.py\n\n# Terminal 2: Monitor SLAM status\nros2 topic echo /visual_slam/status\n\n# Terminal 3: View odometry\nros2 topic echo /visual_slam/odometry\n"})}),"\n",(0,i.jsx)(e.hr,{}),"\n",(0,i.jsx)(e.h2,{id:"part-4-nav2-navigation-stack",children:"Part 4: Nav2 Navigation Stack"}),"\n",(0,i.jsx)(e.h3,{id:"nav2-configuration",children:"Nav2 Configuration"}),"\n",(0,i.jsxs)(e.p,{children:["Create ",(0,i.jsx)(e.code,{children:"~/ros2_ws/config/nav2_params.yaml"}),":"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-yaml",children:'amcl:\n  ros__parameters:\n    use_sim_time: False\n    alpha1: 0.2      # Rotation noise from rotation\n    alpha2: 0.2      # Rotation noise from translation\n    alpha3: 0.2      # Translation noise from translation\n    alpha4: 0.2      # Translation noise from rotation\n    z_max: 4.0\n    z_min: 0.05\n    z_rand: 0.05\n    scan_matching_uncertainty: 0.1\n\nbt_navigator:\n  ros__parameters:\n    use_sim_time: False\n    global_frame: map\n    robot_base_frame: base_link\n    odom_topic: /visual_slam/odometry\n    bt_xml_filename: "navigate_w_replanning_and_recovery.xml"\n    default_nav_to_pose_bt_xml: "navigate_to_pose.xml"\n    plugin_lib_names:\n      - nav2_compute_path_to_pose_action_bt_node\n      - nav2_compute_path_through_poses_action_bt_node\n      - nav2_follow_path_action_bt_node\n      - nav2_spin_action_bt_node\n      - nav2_wait_action_bt_node\n      - nav2_assisted_teleop_action_bt_node\n      - nav2_back_up_action_bt_node\n      - nav2_drive_on_heading_bt_node\n      - nav2_clear_costmap_service_bt_node\n      - nav2_is_stopped_condition_bt_node\n      - nav2_goal_updated_condition_bt_node\n      - nav2_initial_pose_received_condition_bt_node\n      - nav2_reinitialize_global_localization_service_bt_node\n      - nav2_rate_controller_bt_node\n      - nav2_distance_controller_bt_node\n      - nav2_speed_controller_bt_node\n      - nav2_truncate_path_action_bt_node\n      - nav2_truncate_path_local_action_bt_node\n      - nav2_goal_checker_selector_bt_node\n      - nav2_controller_selector_bt_node\n      - nav2_goal_updater_node_bt_node\n      - nav2_would_a_loop_be_formed_condition_bt_node\n      - nav2_if_led_bt_node\n      - nav2_sleep_bt_node\n      - nav2_wait_uptime_bt_node\n\ncontroller_server:\n  ros__parameters:\n    use_sim_time: False\n    controller_frequency: 10.0  # Lower for Jetson\n    min_x_velocity_threshold: 0.001\n    min_y_velocity_threshold: 0.5\n    min_theta_velocity_threshold: 0.001\n    failure_tolerance: 0.3\n    progress_checker_plugin: "progress_checker"\n    goal_checker_plugins: ["general_goal_checker"]\n    controller_plugins: ["FollowPath"]\n\n    # Progress checker\n    progress_checker:\n      plugin: "nav2_controller::SimpleProgressChecker"\n      required_movement_radius: 0.5\n      movement_time_allowance: 10.0\n\n    # Goal checker\n    general_goal_checker:\n      stateful: True\n      plugin: "nav2_controller::SimpleGoalChecker"\n      xy_goal_tolerance: 0.25\n      yaw_goal_tolerance: 0.25\n      stateful: true\n\n    # DWA (Dynamic Window Approach) local planner\n    FollowPath:\n      plugin: "nav2_regulated_pure_pursuit_controller::RegulatedPurePursuitController"\n      desired_linear_vel: 0.5    # m/s\n      lookahead_dist: 0.6        # meters\n      min_approach_linear_vel: -0.05\n      approach_velocity_scaling_dist: 1.0\n      max_allowed_time_error: 1.0\n      use_velocity_scaled_lookahead_dist: false\n      min_lookahead_dist: 0.3\n      max_lookahead_dist: 0.9\n      lookahead_time: 1.5\n      use_approach_linear_velocity_scaling: true\n      max_allowed_time_error: 1.0\n      use_regulated_linear_velocity_scaling: true\n      use_cost_regulated_linear_velocity_scaling: false\n      regulated_linear_scaling_min_radius: 0.9\n      regulated_linear_scaling_min_speed: 0.25\n      use_rotate_to_heading: true\n      rotate_to_heading_min_angle: 0.785\n      max_angular_accel: 3.2\n      max_robot_pose_search_dist: 2.0\n      cost_scaling_dist: 0.6\n      cost_scaling_gain: 1.0\n      inflation_cost_scaling_gain: 3.0\n\nplanner_server:\n  ros__parameters:\n    expected_planner_frequency: 20.0\n    use_sim_time: False\n    planner_plugins: ["GridBased"]\n    GridBased:\n      plugin: "nav2_navfn_planner::NavfnPlanner"\n      tolerance: 0.5\n      use_astar: true\n      allow_unknown: true\n\ncostmap_server:\n  ros__parameters:\n    update_frequency: 5.0  # Lower frequency for Jetson\n    publish_frequency: 2.0\n    global_frame: map\n    robot_base_frame: base_link\n    use_sim_time: False\n    rolling_window: true\n    width: 100\n    height: 100\n    resolution: 0.05\n    robot_radius: 0.22\n    plugins: ["static_layer", "obstacle_layer", "inflation_layer"]\n    inflation_layer:\n      plugin: "nav2_costmap_2d::InflationLayer"\n      cost_scaling_factor: 3.0\n      inflation_radius: 0.55\n    obstacle_layer:\n      plugin: "nav2_costmap_2d::ObstacleLayer"\n      observation_sources: scan\n      scan:\n        topic: /scan\n        max_obstacle_height: 2.0\n        clearing: True\n        marking: True\n        data_type: "LaserScan"\n        raytrace_max_range: 3.0\n        raytrace_min_range: 0.0\n        obstacle_max_range: 2.5\n        obstacle_min_range: 0.0\n    static_layer:\n      plugin: "nav2_costmap_2d::StaticLayer"\n      map_subscribe_transient_local: True\n'})}),"\n",(0,i.jsx)(e.h3,{id:"nav2-launch-file",children:"Nav2 Launch File"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"#!/usr/bin/env python3\n\"\"\"\nLaunch Nav2 navigation stack\n\"\"\"\n\nimport os\nfrom ament_index_python.packages import get_package_share_directory\nfrom launch import LaunchDescription\nfrom launch_ros.actions import Node\n\n\ndef generate_launch_description():\n    nav2_dir = get_package_share_directory('nav2_bringup')\n    config_dir = os.path.expanduser('~/ros2_ws/config')\n\n    return LaunchDescription([\n        # Map server\n        Node(\n            package='nav2_map_server',\n            executable='map_server',\n            name='map_server',\n            output='screen',\n            parameters=[{\n                'yaml_filename': os.path.join(config_dir, 'occupancy_map.yaml'),\n            }]\n        ),\n\n        # Localization (AMCL)\n        Node(\n            package='nav2_amcl',\n            executable='amcl',\n            name='amcl',\n            output='screen',\n            parameters=[os.path.join(config_dir, 'nav2_params.yaml')],\n        ),\n\n        # Path planning\n        Node(\n            package='nav2_planner',\n            executable='planner_server',\n            name='planner_server',\n            output='screen',\n            parameters=[os.path.join(config_dir, 'nav2_params.yaml')],\n        ),\n\n        # Local controller\n        Node(\n            package='nav2_controller',\n            executable='controller_server',\n            name='controller_server',\n            output='screen',\n            parameters=[os.path.join(config_dir, 'nav2_params.yaml')],\n        ),\n\n        # Navigation behavior tree\n        Node(\n            package='nav2_bt_navigator',\n            executable='bt_navigator',\n            name='bt_navigator',\n            output='screen',\n            parameters=[{\n                'bt_xml_filename': os.path.join(nav2_dir, 'behavior_trees', 'navigate_w_replanning_and_recovery.xml'),\n            }]\n        ),\n\n        # Navigation lifecycle manager\n        Node(\n            package='nav2_lifecycle_manager',\n            executable='lifecycle_manager',\n            name='lifecycle_manager_navigation',\n            output='screen',\n            parameters=[{\n                'use_sim_time': False,\n                'autostart': True,\n                'node_names': ['planner_server', 'controller_server', 'bt_navigator']\n            }]\n        ),\n    ])\n"})}),"\n",(0,i.jsx)(e.hr,{}),"\n",(0,i.jsx)(e.h2,{id:"part-5-end-to-end-vslam--navigation",children:"Part 5: End-to-End VSLAM + Navigation"}),"\n",(0,i.jsx)(e.h3,{id:"complete-system-script",children:"Complete System Script"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\n"""\nEnd-to-end VSLAM + Navigation system\nIntegrates visual SLAM mapping with autonomous navigation\n"""\n\nimport rclpy\nfrom rclpy.node import Node\nfrom nav_msgs.msg import OccupancyGrid, Odometry\nfrom geometry_msgs.msg import PoseWithCovarianceStamped, PoseStamped\nimport math\n\n\nclass SLAMNavigationSystem(Node):\n    """Combines SLAM mapping with autonomous navigation"""\n\n    def __init__(self):\n        super().__init__(\'slam_navigation_system\')\n\n        # Subscribe to SLAM outputs\n        self.odometry_sub = self.create_subscription(\n            Odometry,\n            \'/visual_slam/odometry\',\n            self.odometry_callback,\n            10\n        )\n\n        self.map_sub = self.create_subscription(\n            OccupancyGrid,\n            \'/occupancy_grid\',\n            self.map_callback,\n            10\n        )\n\n        # Publish navigation goals\n        self.goal_pub = self.create_publisher(\n            PoseStamped,\n            \'/goal_pose\',\n            10\n        )\n\n        self.current_position = None\n        self.current_map = None\n\n        self.get_logger().info(\'SLAM Navigation System initialized\')\n\n    def odometry_callback(self, msg):\n        """Update current robot position"""\n        self.current_position = msg.pose.pose.position\n        self.get_logger().debug(\n            f\'Robot position: x={self.current_position.x:.2f}, \'\n            f\'y={self.current_position.y:.2f}\'\n        )\n\n    def map_callback(self, msg):\n        """Update occupancy map"""\n        self.current_map = msg\n        occupied_cells = sum(1 for cell in msg.data if cell > 50)\n        self.get_logger().info(\n            f\'Map updated: {msg.info.width}x{msg.info.height}, \'\n            f\'{occupied_cells} occupied cells\'\n        )\n\n    def send_navigation_goal(self, goal_x, goal_y, goal_yaw=0.0):\n        """Send goal to Nav2 navigation system"""\n        goal = PoseStamped()\n        goal.header.frame_id = \'map\'\n        goal.header.stamp = self.get_clock().now().to_msg()\n\n        goal.pose.position.x = goal_x\n        goal.pose.position.y = goal_y\n        goal.pose.position.z = 0.0\n\n        # Convert yaw to quaternion\n        goal.pose.orientation.x = 0.0\n        goal.pose.orientation.y = 0.0\n        goal.pose.orientation.z = math.sin(goal_yaw / 2)\n        goal.pose.orientation.w = math.cos(goal_yaw / 2)\n\n        self.goal_pub.publish(goal)\n        self.get_logger().info(f\'\u2705 Goal sent: ({goal_x:.2f}, {goal_y:.2f})\')\n\n    def explore_environment(self):\n        """Automatically explore environment by sending sequential goals"""\n        exploration_sequence = [\n            (1.0, 0.0, 0.0),      # Move forward 1m\n            (1.0, 1.0, math.pi/4),  # Move diagonal\n            (0.0, 1.0, math.pi/2),  # Move left\n            (-1.0, 0.0, math.pi),   # Move back\n        ]\n\n        for goal_x, goal_y, goal_yaw in exploration_sequence:\n            self.send_navigation_goal(goal_x, goal_y, goal_yaw)\n            self.get_logger().info(f\'Exploring: ({goal_x}, {goal_y})\')\n\n            # Wait for goal completion\n            import time\n            time.sleep(10)\n\n\ndef main(args=None):\n    rclpy.init(args=args)\n    system = SLAMNavigationSystem()\n\n    # Run automated exploration\n    system.explore_environment()\n\n    system.destroy_node()\n    rclpy.shutdown()\n\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,i.jsx)(e.hr,{}),"\n",(0,i.jsx)(e.h2,{id:"hands-on-exercise",children:"Hands-On Exercise"}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Task"}),": Deploy VSLAM on Jetson, map an indoor environment, and navigate autonomously."]}),"\n",(0,i.jsx)(e.h3,{id:"step-1-launch-vslam",children:"Step 1: Launch VSLAM"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-bash",children:"ros2 launch ~/ros2_ws/launch/visual_slam.launch.py\n"})}),"\n",(0,i.jsx)(e.h3,{id:"step-2-map-environment",children:"Step 2: Map Environment"}),"\n",(0,i.jsx)(e.p,{children:"Walk robot around room for 2-3 minutes while SLAM maps:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Observe RViz showing feature tracking"}),"\n",(0,i.jsx)(e.li,{children:"Watch occupancy grid build"}),"\n",(0,i.jsx)(e.li,{children:"Check loop closure detected"}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"step-3-save-map",children:"Step 3: Save Map"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-bash",children:"ros2 service call /map_server/save_map std_srvs/Empty\n# Saved to: ~/map.pgm and ~/map.yaml\n"})}),"\n",(0,i.jsx)(e.h3,{id:"step-4-launch-navigation",children:"Step 4: Launch Navigation"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-bash",children:"ros2 launch ~/ros2_ws/launch/nav2_bringup.launch.py map:=~/map.yaml\n"})}),"\n",(0,i.jsx)(e.h3,{id:"step-5-send-navigation-goals",children:"Step 5: Send Navigation Goals"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-bash",children:"python3 ~/slam_navigation_system.py\n"})}),"\n",(0,i.jsx)(e.h3,{id:"exercises",children:"Exercises"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Mapping Accuracy"}),": Compare SLAM map to actual floor plan (measure error)"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Loop Closure"}),": Revisit starting position and check loop closure detection"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Autonomous Exploration"}),": Implement frontier-based exploration"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Collision Avoidance"}),": Add obstacles and verify costmap adjustment"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Performance"}),": Profile CPU/memory on Jetson Orin Nano"]}),"\n"]}),"\n",(0,i.jsx)(e.hr,{}),"\n",(0,i.jsx)(e.h2,{id:"common-issues--solutions",children:"Common Issues & Solutions"}),"\n",(0,i.jsxs)(e.table,{children:[(0,i.jsx)(e.thead,{children:(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.th,{children:"Issue"}),(0,i.jsx)(e.th,{children:"Cause"}),(0,i.jsx)(e.th,{children:"Solution"})]})}),(0,i.jsxs)(e.tbody,{children:[(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:"Low feature count"}),(0,i.jsx)(e.td,{children:"Poor lighting"}),(0,i.jsx)(e.td,{children:"Improve illumination or use depth + RGB"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:"Loop closure failure"}),(0,i.jsx)(e.td,{children:"Texture-less environment"}),(0,i.jsx)(e.td,{children:"Use visual features from different angles"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:"Navigation oscillation"}),(0,i.jsx)(e.td,{children:"Controller gains wrong"}),(0,i.jsx)(e.td,{children:"Tune nav2_params.yaml controller settings"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:"Memory full on Jetson"}),(0,i.jsx)(e.td,{children:"Map too large"}),(0,i.jsx)(e.td,{children:"Reduce map resolution or use rolling window"})]}),(0,i.jsxs)(e.tr,{children:[(0,i.jsx)(e.td,{children:"SLAM drift"}),(0,i.jsx)(e.td,{children:"Accumulated error"}),(0,i.jsx)(e.td,{children:"Loop closure helps; revisit areas"})]})]})]}),"\n",(0,i.jsx)(e.hr,{}),"\n",(0,i.jsx)(e.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,i.jsxs)(e.p,{children:["\u2705 ",(0,i.jsx)(e.strong,{children:"VSLAM = Localization + Mapping"}),": Simultaneous solving of both problems"]}),"\n",(0,i.jsxs)(e.p,{children:["\u2705 ",(0,i.jsx)(e.strong,{children:"Hardware Acceleration"}),": Isaac ROS uses Jetson's Tensor cores for 10x speedup"]}),"\n",(0,i.jsxs)(e.p,{children:["\u2705 ",(0,i.jsx)(e.strong,{children:"Visual Features"}),": ORB features enable real-time, robust tracking"]}),"\n",(0,i.jsxs)(e.p,{children:["\u2705 ",(0,i.jsx)(e.strong,{children:"Loop Closure"}),": Neural networks detect revisited areas to eliminate drift"]}),"\n",(0,i.jsxs)(e.p,{children:["\u2705 ",(0,i.jsx)(e.strong,{children:"Nav2 Integration"}),": Standardized ROS 2 navigation stack with SLAM output"]}),"\n",(0,i.jsxs)(e.p,{children:["\u2705 ",(0,i.jsx)(e.strong,{children:"Edge Deployment"}),": Real-time VSLAM on Jetson Orin Nano (40 TOPS)"]}),"\n",(0,i.jsxs)(e.p,{children:["\u2705 ",(0,i.jsx)(e.strong,{children:"Autonomous Navigation"}),": Combines mapping + planning + control"]}),"\n",(0,i.jsx)(e.hr,{}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Next Lesson"}),": ",(0,i.jsx)(e.a,{href:"/physical-ai-textbook/docs/chapter-3/3-3-computer-vision-isaac-ros",children:"Lesson 3.3: Computer Vision with Isaac ROS"})]}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Questions?"})," See ",(0,i.jsx)(e.a,{href:"/physical-ai-textbook/docs/faq",children:"FAQ"})," or ",(0,i.jsx)(e.a,{href:"https://github.com/physical-ai-course/physical-ai-textbook/discussions",children:"GitHub Discussions"})]})]})}function u(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(d,{...n})}):d(n)}}}]);